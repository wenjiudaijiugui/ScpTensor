{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Batch Effect Correction with ComBat\n",
    "\n",
    "**ScpTensor v0.1.0-beta**\n",
    "\n",
    "This tutorial demonstrates batch effect correction using the ComBat method. Batch effects are technical variations that can obscure biological signals in single-cell proteomics data.\n",
    "\n",
    "### What you will learn:\n",
    "\n",
    "1. **Understanding Batch Effects** - How to detect and visualize batch effects\n",
    "2. **Data Preparation** - Preprocessing before batch correction\n",
    "3. **ComBat Correction** - Apply empirical Bayes batch correction\n",
    "4. **Integration Verification** - Assess correction quality\n",
    "5. **Before/After Visualization** - Compare results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# ScpTensor imports\n",
    "from scptensor.core import ScpContainer, Assay, ScpMatrix\n",
    "from scptensor.normalization import log_normalize\n",
    "from scptensor.impute import knn\n",
    "from scptensor.integration import combat\n",
    "from scptensor.dim_reduction import pca\n",
    "from scptensor.viz.recipes import embedding, qc_completeness\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Data with Strong Batch Effects\n",
    "\n",
    "We'll create synthetic data with:\n",
    "- **3 batches** with strong technical variation\n",
    "- **2 biological groups** (distributed across batches)\n",
    "- **Missing values** following realistic patterns\n",
    "\n",
    "The batch effect will be intentionally strong so we can clearly see the correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batched_data(n_samples=300, n_features=500, n_batches=3):\n",
    "    \"\"\"\n",
    "    Generate synthetic SCP data with strong batch effects.\n",
    "    \n",
    "    The batch effect includes:\n",
    "    - Additive shift (different baseline per batch)\n",
    "    - Multiplicative scaling (different variance per batch)\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create sample metadata\n",
    "    samples_per_batch = n_samples // n_batches\n",
    "    batches = []\n",
    "    groups = []\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        batch_name = f\"Batch{i+1}\"\n",
    "        batches.extend([batch_name] * samples_per_batch)\n",
    "        # Distribute groups across batches\n",
    "        group_labels = ['GroupA'] * (samples_per_batch // 2) + ['GroupB'] * (samples_per_batch - samples_per_batch // 2)\n",
    "        groups.extend(group_labels)\n",
    "    \n",
    "    obs = pl.DataFrame({\n",
    "        'sample_id': [f'S{i+1:03d}' for i in range(n_samples)],\n",
    "        'batch': batches,\n",
    "        'group': groups\n",
    "    })\n",
    "    \n",
    "    # Generate base expression (biological signal)\n",
    "    X_bio = np.random.lognormal(mean=2, sigma=0.3, size=(n_samples, n_features))\n",
    "    # Add group effect (first 50 proteins are higher in GroupB)\n",
    "    group_mask = np.array([g == 'GroupB' for g in groups])\n",
    "    X_bio[group_mask, :50] *= 1.8\n",
    "    \n",
    "    # Add strong batch effects\n",
    "    X_batched = X_bio.copy()\n",
    "    for i, batch in enumerate(['Batch1', 'Batch2', 'Batch3']):\n",
    "        mask = np.array([b == batch for b in batches])\n",
    "        # Different baseline per batch (additive)\n",
    "        baseline_shift = [0, 0.5, 1.0][i]  # Batch3 has highest baseline\n",
    "        # Different scaling per batch (multiplicative)\n",
    "        scale_factor = [1.0, 1.5, 2.0][i]  # Batch3 has highest variance\n",
    "        X_batched[mask] = X_batched[mask] * scale_factor + baseline_shift\n",
    "    \n",
    "    # Introduce missing values\n",
    "    X_observed = X_batched.copy()\n",
    "    M = np.zeros((n_samples, n_features), dtype=int)\n",
    "    \n",
    "    # LOD missing (15%)\n",
    "    threshold = np.percentile(X_batched, 15)\n",
    "    lod_mask = X_batched < threshold\n",
    "    X_observed[lod_mask] = 0\n",
    "    M[lod_mask] = 2\n",
    "    \n",
    "    # Random missing (25%)\n",
    "    n_random_missing = int(n_samples * n_features * 0.25)\n",
    "    valid_indices = np.argwhere(M == 0)\n",
    "    random_indices = valid_indices[np.random.choice(len(valid_indices), size=n_random_missing, replace=False)]\n",
    "    X_observed[random_indices[:, 0], random_indices[:, 1]] = 0\n",
    "    M[random_indices[:, 0], random_indices[:, 1]] = 1\n",
    "    \n",
    "    # Create feature metadata\n",
    "    var = pl.DataFrame({\n",
    "        'protein_id': [f'P{i+1:04d}' for i in range(n_features)],\n",
    "        '_index': [f'P{i+1:04d}' for i in range(n_features)]\n",
    "    })\n",
    "    \n",
    "    matrix = ScpMatrix(X=X_observed, M=M)\n",
    "    assay = Assay(var=var, layers={'raw': matrix}, feature_id_col='protein_id')\n",
    "    \n",
    "    container = ScpContainer(\n",
    "        assays={'protein': assay},\n",
    "        obs=obs.with_columns(pl.Series(name=\"_index\", values=obs[\"sample_id\"].to_list())),\n",
    "        sample_id_col='sample_id'\n",
    "    )\n",
    "    \n",
    "    return container\n",
    "\n",
    "# Generate data\n",
    "container = generate_batched_data(n_samples=300, n_features=500, n_batches=3)\n",
    "\n",
    "print(f\"Generated data with strong batch effects:\")\n",
    "print(f\"  - Samples: {container.n_samples}\")\n",
    "print(f\"  - Features: {container.n_features}\")\n",
    "print(f\"  - Batches: {container.obs['batch'].unique().to_list()}\")\n",
    "print(f\"  - Groups: {container.obs['group'].unique().to_list()}\")\n",
    "print(f\"  - Missing rate: {np.mean(container.assays['protein'].layers['raw'].M != 0):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Pipeline\n",
    "\n",
    "Before batch correction, we need to:\n",
    "1. Normalize the data (log transform)\n",
    "2. Impute missing values (required for most batch correction methods)\n",
    "3. Run PCA to visualize the batch effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Log normalization\n",
    "container = log_normalize(\n",
    "    container,\n",
    "    assay_name='protein',\n",
    "    base_layer='raw',\n",
    "    new_layer_name='log',\n",
    "    base=2.0,\n",
    "    offset=1.0\n",
    ")\n",
    "print(\"Step 1: Log normalization complete\")\n",
    "\n",
    "# Step 2: KNN imputation\n",
    "container = knn(\n",
    "    container,\n",
    "    assay_name='protein',\n",
    "    base_layer='log',\n",
    "    new_layer_name='imputed',\n",
    "    k=5\n",
    ")\n",
    "print(\"Step 2: KNN imputation complete\")\n",
    "\n",
    "# Step 3: PCA for visualization\n",
    "container = pca(\n",
    "    container,\n",
    "    assay_name='protein',\n",
    "    base_layer_name='imputed',\n",
    "    new_assay_name='pca_before',\n",
    "    n_components=10,\n",
    "    center=True,\n",
    "    scale=False\n",
    ")\n",
    "print(\"Step 3: PCA complete\")\n",
    "\n",
    "print(f\"\\nAvailable layers: {list(container.assays['protein'].layers.keys())}\")\n",
    "print(f\"Available assays: {list(container.assays.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Batch Effect (Before Correction)\n",
    "\n",
    "Let's examine the data before batch correction. We expect to see samples clustering by batch rather than biological group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA visualization before correction\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "embedding(container, basis='pca_before', color='batch')\n",
    "plt.title(\"Before ComBat: By Batch\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "embedding(container, basis='pca_before', color='group')\n",
    "plt.title(\"Before ComBat: By Biological Group\")\n",
    "\n",
    "plt.sca(axes[2])\n",
    "# Create a combined label for better visualization\n",
    "combined = container.obs['batch'] + '_' + container.obs['group']\n",
    "container_copy = container\n",
    "container_copy.obs = container_copy.obs.with_columns(pl.Series('batch_group', combined))\n",
    "embedding(container_copy, basis='pca_before', color='batch_group')\n",
    "plt.title(\"Before ComBat: Batch + Group\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify Batch Effect\n",
    "\n",
    "We can quantify the batch effect by measuring how much variance is explained by batch vs biological group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_batch_effect(container, pca_assay='pca_before'):\n",
    "    \"\"\"\n",
    "    Quantify batch effect using PCA coordinates.\n",
    "    Returns the ratio of within-batch distance to between-batch distance.\n",
    "    \"\"\"\n",
    "    scores = container.assays[pca_assay].layers['scores'].X[:, :2]\n",
    "    \n",
    "    # Calculate within-batch distances (samples within same batch should be similar)\n",
    "    batches = container.obs['batch'].to_numpy()\n",
    "    unique_batches = np.unique(batches)\n",
    "    \n",
    "    within_distances = []\n",
    "    for batch in unique_batches:\n",
    "        batch_scores = scores[batches == batch]\n",
    "        # Average pairwise distance within batch\n",
    "        if len(batch_scores) > 1:\n",
    "            dists = pairwise_distances(batch_scores)\n",
    "            within_distances.append(np.mean(dists))\n",
    "    \n",
    "    # Calculate between-batch distances\n",
    "    between_distances = []\n",
    "    for i, batch1 in enumerate(unique_batches):\n",
    "        for batch2 in unique_batches[i+1:]:\n",
    "            scores1 = scores[batches == batch1]\n",
    "            scores2 = scores[batches == batch2]\n",
    "            dists = pairwise_distances(scores1, scores2)\n",
    "            between_distances.append(np.mean(dists))\n",
    "    \n",
    "    within_mean = np.mean(within_distances)\n",
    "    between_mean = np.mean(between_distances)\n",
    "    \n",
    "    return {\n",
    "        'within_batch_distance': within_mean,\n",
    "        'between_batch_distance': between_mean,\n",
    "        'batch_severity': between_mean / within_mean if within_mean > 0 else float('inf')\n",
    "    }\n",
    "\n",
    "metrics_before = quantify_batch_effect(container, 'pca_before')\n",
    "print(\"Batch Effect Quantification (Before Correction):\")\n",
    "print(f\"  Within-batch distance:  {metrics_before['within_batch_distance']:.4f}\")\n",
    "print(f\"  Between-batch distance: {metrics_before['between_batch_distance']:.4f}\")\n",
    "print(f\"  Severity ratio:         {metrics_before['batch_severity']:.4f}\")\n",
    "print(\"\\n(Severity > 1 indicates samples cluster by batch more than biology)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply ComBat Batch Correction\n",
    "\n",
    "**ComBat** uses an empirical Bayes approach to adjust for batch effects while preserving biological signals.\n",
    "\n",
    "**How it works:**\n",
    "1. Standardize data within each batch\n",
    "2. Estimate batch effect parameters (additive and multiplicative)\n",
    "3. Apply empirical Bayes shrinkage to stabilize estimates\n",
    "4. Adjust data to remove batch effects\n",
    "\n",
    "**Key parameters:**\n",
    "- `batch_key`: Column name in obs containing batch labels\n",
    "- `covariates`: Optional biological variables to preserve (e.g., 'group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ComBat correction\n",
    "# We use 'group' as a covariate to preserve the biological signal\n",
    "container = combat(\n",
    "    container,\n",
    "    batch_key='batch',\n",
    "    assay_name='protein',\n",
    "    base_layer='imputed',\n",
    "    new_layer_name='combat_corrected',\n",
    "    covariates=['group']  # Preserve biological group differences\n",
    ")\n",
    "\n",
    "print(\"ComBat batch correction complete!\")\n",
    "print(f\"\\nAvailable layers: {list(container.assays['protein'].layers.keys())}\")\n",
    "\n",
    "# Verify the correction\n",
    "X_before = container.assays['protein'].layers['imputed'].X\n",
    "X_after = container.assays['protein'].layers['combat_corrected'].X\n",
    "\n",
    "print(f\"\\nData shape unchanged: {X_before.shape} -> {X_after.shape}\")\n",
    "print(f\"Data range before: [{np.min(X_before):.2f}, {np.max(X_before):.2f}]\")\n",
    "print(f\"Data range after:  [{np.min(X_after):.2f}, {np.max(X_after):.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results (After Correction)\n",
    "\n",
    "Now let's run PCA on the corrected data and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA on corrected data\n",
    "container = pca(\n",
    "    container,\n",
    "    assay_name='protein',\n",
    "    base_layer_name='combat_corrected',\n",
    "    new_assay_name='pca_after',\n",
    "    n_components=10,\n",
    "    center=True,\n",
    "    scale=False\n",
    ")\n",
    "\n",
    "print(\"PCA on corrected data complete!\")\n",
    "\n",
    "# PCA visualization after correction\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "plt.sca(axes[0])\n",
    "embedding(container, basis='pca_after', color='batch')\n",
    "plt.title(\"After ComBat: By Batch\")\n",
    "\n",
    "plt.sca(axes[1])\n",
    "embedding(container, basis='pca_after', color='group')\n",
    "plt.title(\"After ComBat: By Biological Group\")\n",
    "\n",
    "plt.sca(axes[2])\n",
    "container_copy.obs = container_copy.obs.with_columns(pl.Series('batch_group', combined))\n",
    "embedding(container_copy, basis='pca_after', color='batch_group')\n",
    "plt.title(\"After ComBat: Batch + Group\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Before/After Comparison\n",
    "\n",
    "Let's compare the results side by side to clearly see the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Top row: Before correction\n",
    "plt.sca(axes[0, 0])\n",
    "embedding(container, basis='pca_before', color='batch')\n",
    "plt.title(\"BEFORE: Colored by Batch\")\n",
    "\n",
    "plt.sca(axes[0, 1])\n",
    "embedding(container, basis='pca_before', color='group')\n",
    "plt.title(\"BEFORE: Colored by Group\")\n",
    "\n",
    "# Bottom row: After correction\n",
    "plt.sca(axes[1, 0])\n",
    "embedding(container, basis='pca_after', color='batch')\n",
    "plt.title(\"AFTER: Colored by Batch\")\n",
    "\n",
    "plt.sca(axes[1, 1])\n",
    "embedding(container, basis='pca_after', color='group')\n",
    "plt.title(\"AFTER: Colored by Group\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quantify Correction Quality\n",
    "\n",
    "Let's measure how well the batch correction worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify batch effect after correction\n",
    "metrics_after = quantify_batch_effect(container, 'pca_after')\n",
    "\n",
    "print(\"Batch Effect Quantification:\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"{'Metric':<30} {'Before':>12} {'After':>12}\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Within-batch distance':<30} {metrics_before['within_batch_distance']:>12.4f} {metrics_after['within_batch_distance']:>12.4f}\")\n",
    "print(f\"{'Between-batch distance':<30} {metrics_before['between_batch_distance']:>12.4f} {metrics_after['between_batch_distance']:>12.4f}\")\n",
    "print(f\"{'Severity ratio':<30} {metrics_before['batch_severity']:>12.4f} {metrics_after['batch_severity']:>12.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate improvement\n",
    "severity_reduction = (metrics_before['batch_severity'] - metrics_after['batch_severity']) / metrics_before['batch_severity'] * 100\n",
    "print(f\"\\nSeverity reduction: {severity_reduction:.1f}%\")\n",
    "\n",
    "if severity_reduction > 50:\n",
    "    print(\"Result: Excellent batch correction!\")\n",
    "elif severity_reduction > 20:\n",
    "    print(\"Result: Good batch correction.\")\n",
    "else:\n",
    "    print(\"Result: Batch effect still present (consider more aggressive correction).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### What we covered:\n",
    "\n",
    "| Step | Description | Function |\n",
    "|------|-------------|----------|\n",
    "| 1. Data Generation | Created synthetic data with strong batch effects | `generate_batched_data()` |\n",
    "| 2. Normalization | Log transform for variance stabilization | `log_normalize()` |\n",
    "| 3. Imputation | Fill missing values | `knn()` |\n",
    "| 4. Pre-PCA | Visualize batch effect before correction | `pca()` |\n",
    "| 5. Batch Correction | ComBat empirical Bayes correction | `combat()` |\n",
    "| 6. Post-PCA | Visualize corrected data | `pca()` |\n",
    "| 7. Verification | Quantify correction quality | `quantify_batch_effect()` |\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Batch Effects Matter**: Technical variation can mask biological signals\n",
    "2. **ComBat Parameters**:\n",
    "   - `batch_key`: Required - identifies batch membership\n",
    "   - `covariates`: Optional - preserves biological variables\n",
    "   - Always impute missing values before correction\n",
    "\n",
    "3. **Verification is Essential**:\n",
    "   - Visual inspection (PCA plots)\n",
    "   - Quantitative metrics (batch severity ratio)\n",
    "   - Check that biological signals are preserved\n",
    "\n",
    "4. **When to Use Batch Correction**:\n",
    "   - Multiple experimental batches\n",
    "   - Different instruments or protocols\n",
    "   - Data collected at different times\n",
    "   - When PCA shows batch clustering\n",
    "\n",
    "### Next Steps:\n",
    "- Try adjusting ComBat parameters (with/without covariates)\n",
    "- Explore other integration methods (`harmony`, `scanorama`, `mnn`)\n",
    "- Apply to your own single-cell proteomics data\n",
    "- Check out Tutorial 1 for the basic workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "file mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

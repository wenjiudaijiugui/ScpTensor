{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 07: Feature Selection\n",
    "\n",
    "This tutorial covers feature selection methods for single-cell proteomics data, helping you identify the most informative proteins/peptides for downstream analysis.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand the importance of feature selection in single-cell analysis\n",
    "- Select highly variable features using HVG methods\n",
    "- Apply variance stabilizing transformation (VST) for feature selection\n",
    "- Filter features based on dropout rates\n",
    "- Use model-based feature selection methods\n",
    "- Perform PCA loading-based feature selection\n",
    "- Compare and evaluate different feature selection strategies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import required libraries and load a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Apply SciencePlots style\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "\n",
    "# Import ScpTensor\n",
    "import scptensor\n",
    "from scptensor import (\n",
    "    get_dropout_stats,\n",
    "    # Normalization\n",
    "    norm_log,\n",
    "    select_by_dispersion,\n",
    "    select_by_dropout,\n",
    "    select_by_model_importance,\n",
    "    select_by_pca_loadings,\n",
    "    select_by_vst,\n",
    "    # Feature selection methods\n",
    "    select_hvg,\n",
    ")\n",
    "from scptensor.datasets import load_simulated_scrnaseq_like\n",
    "\n",
    "print(f\"ScpTensor version: {scptensor.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "Load a dataset and apply basic normalization for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "container = load_simulated_scrnaseq_like()\n",
    "\n",
    "print(f\"Dataset loaded: {container}\")\n",
    "print(f\"Samples: {container.n_samples}\")\n",
    "print(f\"Features: {container.assays['proteins'].n_features}\")\n",
    "\n",
    "# Apply log normalization for feature selection\n",
    "container = norm_log(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"raw\",\n",
    "    new_layer_name=\"log\",\n",
    "    base=2.0,\n",
    "    offset=1.0,\n",
    ")\n",
    "\n",
    "print(\"\\nLog normalization completed.\")\n",
    "print(f\"Available layers: {list(container.assays['proteins'].layers.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Why Feature Selection?\n",
    "\n",
    "Feature selection is crucial for single-cell analysis because:\n",
    "\n",
    "1. **Dimensionality Reduction**: Proteomics data often has 1000+ features, but only a subset is informative\n",
    "2. **Noise Reduction**: Removing low-quality features improves signal-to-noise ratio\n",
    "3. **Computational Efficiency**: Fewer features speed up downstream analysis\n",
    "4. **Biological Relevance**: Variable features often represent biologically relevant proteins\n",
    "5. **Improved Clustering**: Feature selection enhances cell type separation\n",
    "\n",
    "Key considerations:\n",
    "- **Highly Variable Features**: Show variation across samples/cells\n",
    "- **Dropout Rate**: Features with high missingness may be less reliable\n",
    "- **Expression Level**: Very low expression features have high technical noise\n",
    "- **Correlation**: Highly correlated features provide redundant information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Highly Variable Genes/Proteins (HVG)\n",
    "\n",
    "HVG selection identifies features with high variability using coefficient of variation (CV) or dispersion metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select HVGs using coefficient of variation\n",
    "n_features_original = container.assays[\"proteins\"].n_features\n",
    "n_top_features = 100  # Select top 100 most variable features\n",
    "\n",
    "container_hvg = select_hvg(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"log\",\n",
    "    n_top_features=n_top_features,\n",
    "    method=\"cv\",  # Options: 'cv' (coefficient of variation) or 'dispersion'\n",
    "    subset=True,  # If True, return filtered container; if False, add annotation\n",
    ")\n",
    "\n",
    "print(\"HVG Selection Results:\")\n",
    "print(f\"  Original features: {n_features_original}\")\n",
    "print(f\"  Selected features: {container_hvg.assays['proteins'].n_features}\")\n",
    "print(f\"  Features removed: {n_features_original - container_hvg.assays['proteins'].n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 HVG Annotation Mode\n",
    "\n",
    "Instead of subsetting, you can annotate features without removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate HVGs without subsetting\n",
    "container_annotated = select_hvg(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"log\",\n",
    "    n_top_features=50,\n",
    "    method=\"cv\",\n",
    "    subset=False,  # Add annotation instead of subsetting\n",
    ")\n",
    "\n",
    "# Check annotations\n",
    "var = container_annotated.assays[\"proteins\"].var\n",
    "if \"highly_variable\" in var.columns:\n",
    "    n_hvg = var[\"highly_variable\"].sum()\n",
    "    print(\"HVG Annotation Results:\")\n",
    "    print(f\"  Total features: {len(var)}\")\n",
    "    print(f\"  Highly variable: {n_hvg}\")\n",
    "    print(f\"  Percentage: {n_hvg / len(var) * 100:.1f}%\")\n",
    "\n",
    "    # View variability scores\n",
    "    if \"variability_score\" in var.columns:\n",
    "        print(\"\\nVariability Score Statistics:\")\n",
    "        print(f\"  Min: {var['variability_score'].min():.4f}\")\n",
    "        print(f\"  Max: {var['variability_score'].max():.4f}\")\n",
    "        print(f\"  Mean: {var['variability_score'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Visualizing HVG Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize mean-variance relationship for HVG selection\n",
    "from scptensor.feature_selection._shared import _compute_mean_var\n",
    "\n",
    "# Compute mean and variance\n",
    "X = container.assays[\"proteins\"].layers[\"log\"].X\n",
    "means, variances = _compute_mean_var(X, axis=0)\n",
    "\n",
    "# Compute coefficient of variation\n",
    "eps = np.finfo(means.dtype).eps\n",
    "cv = np.sqrt(variances) / (means + eps)\n",
    "\n",
    "# Get HVG annotation\n",
    "is_hvg = (\n",
    "    var[\"highly_variable\"].to_numpy()\n",
    "    if \"highly_variable\" in var.columns\n",
    "    else np.zeros(len(means), dtype=bool)\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Mean vs Variance (colored by HVG status)\n",
    "colors = [\"red\" if h else \"lightblue\" for h in is_hvg]\n",
    "axes[0].scatter(means, variances, c=colors, alpha=0.6, s=20)\n",
    "axes[0].set_xlabel(\"Mean Expression\")\n",
    "axes[0].set_ylabel(\"Variance\")\n",
    "axes[0].set_title(\"Mean-Variance Relationship\")\n",
    "axes[0].set_xscale(\"log\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"red\", label=f\"HVG ({is_hvg.sum()})\"),\n",
    "    Patch(facecolor=\"lightblue\", label=f\"Non-HVG ({(~is_hvg).sum()})\"),\n",
    "]\n",
    "axes[0].legend(handles=legend_elements)\n",
    "\n",
    "# CV distribution\n",
    "axes[1].hist(cv, bins=50, color=\"steelblue\", edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].axvline(\n",
    "    cv[is_hvg].min() if is_hvg.sum() > 0 else cv.max(),\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"HVG threshold\",\n",
    ")\n",
    "axes[1].set_xlabel(\"Coefficient of Variation\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].set_title(\"CV Distribution\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/hvg_selection.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"HVG visualization saved to: tutorial_output/hvg_selection.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Variance Stabilizing Transformation (VST)\n",
    "\n",
    "VST selects variable features using the Seurat-style approach, modeling the mean-variance relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features using VST\n",
    "container_vst = select_by_vst(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"log\",\n",
    "    n_top_features=100,\n",
    "    subset=True,\n",
    ")\n",
    "\n",
    "print(\"VST Selection Results:\")\n",
    "print(f\"  Original features: {n_features_original}\")\n",
    "print(f\"  Selected features: {container_vst.assays['proteins'].n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dispersion-Based Selection\n",
    "\n",
    "Select features based on normalized dispersion (variance-to-mean ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features by dispersion\n",
    "container_disp = select_by_dispersion(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"log\",\n",
    "    n_top_features=100,\n",
    "    n_bins=20,  # Number of bins for normalization\n",
    "    subset=True,\n",
    ")\n",
    "\n",
    "print(\"Dispersion Selection Results:\")\n",
    "print(f\"  Original features: {n_features_original}\")\n",
    "print(f\"  Selected features: {container_disp.assays['proteins'].n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dropout-Based Filtering\n",
    "\n",
    "Filter features based on their dropout rate (percentage of missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dropout statistics first\n",
    "dropout_stats = get_dropout_stats(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"raw\",\n",
    ")\n",
    "\n",
    "print(\"Dropout Statistics:\")\n",
    "print(dropout_stats.head(10))\n",
    "\n",
    "# Summary\n",
    "print(\"\\nDropout Rate Summary:\")\n",
    "print(f\"  Mean dropout rate: {dropout_stats['dropout_rate'].mean() * 100:.2f}%\")\n",
    "print(f\"  Median dropout rate: {dropout_stats['dropout_rate'].median() * 100:.2f}%\")\n",
    "print(f\"  Features with >50% dropout: {(dropout_stats['dropout_rate'] > 0.5).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Filter by Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features with high dropout rate\n",
    "container_dropout = select_by_dropout(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"raw\",\n",
    "    max_dropout_rate=0.5,  # Keep features detected in at least 50% of samples\n",
    "    subset=True,\n",
    ")\n",
    "\n",
    "print(\"Dropout Filtering Results:\")\n",
    "print(f\"  Original features: {n_features_original}\")\n",
    "print(f\"  Features after filtering: {container_dropout.assays['proteins'].n_features}\")\n",
    "print(\n",
    "    f\"  Features removed: {n_features_original - container_dropout.assays['proteins'].n_features}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualizing Dropout Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dropout rate distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Dropout rate histogram\n",
    "axes[0].hist(dropout_stats[\"dropout_rate\"], bins=50, color=\"coral\", edgecolor=\"black\")\n",
    "axes[0].axvline(0.5, color=\"red\", linestyle=\"--\", linewidth=2, label=\"50% threshold\")\n",
    "axes[0].set_xlabel(\"Dropout Rate\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].set_title(\"Dropout Rate Distribution\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Mean expression vs dropout rate\n",
    "mean_expr = dropout_stats[\"mean_expression\"].to_numpy()\n",
    "dropout_rate = dropout_stats[\"dropout_rate\"].to_numpy()\n",
    "\n",
    "axes[1].scatter(mean_expr, dropout_rate, alpha=0.5, s=20)\n",
    "axes[1].axhline(0.5, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "axes[1].set_xlabel(\"Mean Expression\")\n",
    "axes[1].set_ylabel(\"Dropout Rate\")\n",
    "axes[1].set_title(\"Mean Expression vs Dropout Rate\")\n",
    "axes[1].set_xscale(\"log\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/dropout_analysis.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Dropout analysis saved to: tutorial_output/dropout_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model-Based Feature Selection\n",
    "\n",
    "Use machine learning models to identify the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features using random forest importance\n",
    "# Note: This requires scikit-learn\n",
    "try:\n",
    "    container_rf = select_by_model_importance(\n",
    "        container=container,\n",
    "        assay_name=\"proteins\",\n",
    "        layer=\"log\",\n",
    "        n_top_features=100,\n",
    "        model_type=\"random_forest\",  # Options: 'random_forest', 'variance_threshold'\n",
    "        random_state=42,\n",
    "        subset=True,\n",
    "    )\n",
    "\n",
    "    print(\"Random Forest Feature Selection Results:\")\n",
    "    print(f\"  Original features: {n_features_original}\")\n",
    "    print(f\"  Selected features: {container_rf.assays['proteins'].n_features}\")\n",
    "except Exception as e:\n",
    "    print(f\"Random forest selection skipped: {e}\")\n",
    "    print(\"(Requires scikit-learn: pip install scikit-learn)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. PCA Loading-Based Selection\n",
    "\n",
    "Select features based on their contribution to principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features by PCA loadings\n",
    "container_pca = select_by_pca_loadings(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer=\"log\",\n",
    "    n_top_features=100,\n",
    "    n_components=10,  # Use first 10 PCs\n",
    "    subset=True,\n",
    ")\n",
    "\n",
    "print(\"PCA Loading-Based Selection Results:\")\n",
    "print(f\"  Original features: {n_features_original}\")\n",
    "print(f\"  Selected features: {container_pca.assays['proteins'].n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Comparing Feature Selection Methods\n",
    "\n",
    "Compare overlap and differences between different feature selection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare selected features from different methods\n",
    "# Get selected feature IDs from each method\n",
    "hvg_ids = set(container_hvg.assays[\"proteins\"].var[\"_index\"].to_list())\n",
    "vst_ids = set(container_vst.assays[\"proteins\"].var[\"_index\"].to_list())\n",
    "disp_ids = set(container_disp.assays[\"proteins\"].var[\"_index\"].to_list())\n",
    "pca_ids = set(container_pca.assays[\"proteins\"].var[\"_index\"].to_list())\n",
    "\n",
    "print(\"Feature Selection Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"HVG: {len(hvg_ids)} features\")\n",
    "print(f\"VST: {len(vst_ids)} features\")\n",
    "print(f\"Dispersion: {len(disp_ids)} features\")\n",
    "print(f\"PCA: {len(pca_ids)} features\")\n",
    "\n",
    "# Calculate overlaps\n",
    "hvg_vst_overlap = len(hvg_ids & vst_ids)\n",
    "hvg_disp_overlap = len(hvg_ids & disp_ids)\n",
    "hvg_pca_overlap = len(hvg_ids & pca_ids)\n",
    "all_overlap = len(hvg_ids & vst_ids & disp_ids & pca_ids)\n",
    "\n",
    "print(\"\\nOverlap with HVG:\")\n",
    "print(f\"  HVG & VST: {hvg_vst_overlap} ({hvg_vst_overlap / len(hvg_ids) * 100:.1f}%)\")\n",
    "print(f\"  HVG & Dispersion: {hvg_disp_overlap} ({hvg_disp_overlap / len(hvg_ids) * 100:.1f}%)\")\n",
    "print(f\"  HVG & PCA: {hvg_pca_overlap} ({hvg_pca_overlap / len(hvg_ids) * 100:.1f}%)\")\n",
    "print(f\"  All four methods: {all_overlap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 UpSet Plot for Feature Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simplified overlap visualization\n",
    "\n",
    "methods = {\n",
    "    \"HVG\": hvg_ids,\n",
    "    \"VST\": vst_ids,\n",
    "    \"Dispersion\": disp_ids,\n",
    "    \"PCA\": pca_ids,\n",
    "}\n",
    "\n",
    "# Calculate pairwise overlaps\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Create overlap matrix\n",
    "method_names = list(methods.keys())\n",
    "n_methods = len(method_names)\n",
    "overlap_matrix = np.zeros((n_methods, n_methods))\n",
    "\n",
    "for i, m1 in enumerate(method_names):\n",
    "    for j, m2 in enumerate(method_names):\n",
    "        if i == j:\n",
    "            overlap_matrix[i, j] = len(methods[m1])\n",
    "        else:\n",
    "            overlap_matrix[i, j] = len(methods[m1] & methods[m2])\n",
    "\n",
    "# Plot heatmap\n",
    "im = ax.imshow(overlap_matrix, cmap=\"Blues\")\n",
    "ax.set_xticks(range(n_methods))\n",
    "ax.set_yticks(range(n_methods))\n",
    "ax.set_xticklabels(method_names)\n",
    "ax.set_yticklabels(method_names)\n",
    "ax.set_title(\"Feature Selection Overlap Matrix\")\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(n_methods):\n",
    "    for j in range(n_methods):\n",
    "        text = ax.text(\n",
    "            j, i, int(overlap_matrix[i, j]), ha=\"center\", va=\"center\", color=\"black\", fontsize=10\n",
    "        )\n",
    "\n",
    "plt.colorbar(im, ax=ax, label=\"Number of Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/feature_selection_overlap.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Overlap visualization saved to: tutorial_output/feature_selection_overlap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Impact of Feature Selection on Clustering\n",
    "\n",
    "Visualize how feature selection affects downstream clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PCA on full vs selected features\n",
    "from scptensor import reduce_pca\n",
    "\n",
    "# Run PCA on full feature set\n",
    "container_full_pca = reduce_pca(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer_name=\"log\",\n",
    "    new_assay_name=\"pca_full\",\n",
    "    n_components=10,\n",
    ")\n",
    "\n",
    "# Run PCA on HVG-selected features\n",
    "container_hvg_pca = reduce_pca(\n",
    "    container=container_hvg,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer_name=\"log\",\n",
    "    new_assay_name=\"pca_hvg\",\n",
    "    n_components=10,\n",
    ")\n",
    "\n",
    "# Get cell type colors\n",
    "cell_types = container.obs[\"cell_type\"].to_numpy()\n",
    "unique_ct = sorted(container.obs[\"cell_type\"].unique().to_list())\n",
    "ct_colors = plt.cm.Set2(np.linspace(0, 1, len(unique_ct)))\n",
    "ct_to_color = dict(zip(unique_ct, ct_colors, strict=False))\n",
    "point_colors = [ct_to_color[ct] for ct in cell_types]\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Full feature PCA\n",
    "pc1_full = container_full_pca.assays[\"pca_full\"].layers[\"scores\"].X[:, 0]\n",
    "pc2_full = container_full_pca.assays[\"pca_full\"].layers[\"scores\"].X[:, 1]\n",
    "axes[0].scatter(pc1_full, pc2_full, c=point_colors, alpha=0.6, s=30)\n",
    "axes[0].set_xlabel(\n",
    "    f\"PC1 ({container_full_pca.assays['pca_full'].var['variance_ratio'][0] * 100:.1f}%)\"\n",
    ")\n",
    "axes[0].set_ylabel(\n",
    "    f\"PC2 ({container_full_pca.assays['pca_full'].var['variance_ratio'][1] * 100:.1f}%)\"\n",
    ")\n",
    "axes[0].set_title(f\"PCA: All Features ({n_features_original})\")\n",
    "\n",
    "# Add legend for full\n",
    "for ct, color in ct_to_color.items():\n",
    "    axes[0].scatter([], [], c=[color], label=ct, s=50)\n",
    "axes[0].legend()\n",
    "\n",
    "# HVG PCA\n",
    "pc1_hvg = container_hvg_pca.assays[\"pca_hvg\"].layers[\"scores\"].X[:, 0]\n",
    "pc2_hvg = container_hvg_pca.assays[\"pca_hvg\"].layers[\"scores\"].X[:, 1]\n",
    "axes[1].scatter(pc1_hvg, pc2_hvg, c=point_colors, alpha=0.6, s=30)\n",
    "axes[1].set_xlabel(\n",
    "    f\"PC1 ({container_hvg_pca.assays['pca_hvg'].var['variance_ratio'][0] * 100:.1f}%)\"\n",
    ")\n",
    "axes[1].set_ylabel(\n",
    "    f\"PC2 ({container_hvg_pca.assays['pca_hvg'].var['variance_ratio'][1] * 100:.1f}%)\"\n",
    ")\n",
    "axes[1].set_title(f\"PCA: HVG Selected ({container_hvg.assays['proteins'].n_features})\")\n",
    "\n",
    "# Add legend for HVG\n",
    "for ct, color in ct_to_color.items():\n",
    "    axes[1].scatter([], [], c=[color], label=ct, s=50)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/pca_feature_selection_comparison.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"PCA comparison saved to: tutorial_output/pca_feature_selection_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Selection Strategy Guidelines\n",
    "\n",
    "### When to Use Each Method:\n",
    "\n",
    "1. **HVG (CV-based)**:\n",
    "   - Best for: General-purpose feature selection\n",
    "   - Works well: When expression varies across conditions\n",
    "   - Fast computation\n",
    "\n",
    "2. **VST (Seurat-style)**:\n",
    "   - Best for: Single-cell RNA-seq style analysis\n",
    "   - Works well: With normalized log-transformed data\n",
    "   - Accounts for mean-variance relationship\n",
    "\n",
    "3. **Dispersion-based**:\n",
    "   - Best for: Features with high variance-to-mean ratio\n",
    "   - Works well: When variance increases with mean\n",
    "\n",
    "4. **Dropout-based**:\n",
    "   - Best for: Removing unreliable features\n",
    "   - Works well: As a pre-filtering step\n",
    "   - Conservative approach\n",
    "\n",
    "5. **PCA loading-based**:\n",
    "   - Best for: Dimensionality reduction focused\n",
    "   - Works well: When using PCA for downstream analysis\n",
    "   - Captures major sources of variation\n",
    "\n",
    "6. **Model-based**:\n",
    "   - Best for: Complex patterns\n",
    "   - Works well: With labeled data (supervised)\n",
    "   - Slower but may capture non-linear relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Best Practices Summary\n",
    "\n",
    "### Recommended Workflow:\n",
    "\n",
    "1. **Pre-filtering** (optional):\n",
    "   - Remove features with very high dropout rates (>80%)\n",
    "   - Remove features with near-zero variance\n",
    "\n",
    "2. **Normalization**:\n",
    "   - Apply log transformation before HVG/VST\n",
    "   - Consider Z-score normalization for some methods\n",
    "\n",
    "3. **Feature Selection**:\n",
    "   - Use HVG or VST as primary method\n",
    "   - Select 1000-2000 features for large datasets\n",
    "   - Select 50-200 features for small datasets\n",
    "\n",
    "4. **Validation**:\n",
    "   - Check biological relevance of selected features\n",
    "   - Compare PCA before/after feature selection\n",
    "   - Assess clustering quality\n",
    "\n",
    "### Common Pitfalls:\n",
    "- **Over-filtering**: Removing too many features loses biological signal\n",
    "- **Under-filtering**: Too many features include noise\n",
    "- **Ignoring batch effects**: Batch-specific features may be selected\n",
    "- **Not validating**: Always check the impact on downstream analysis\n",
    "\n",
    "### Parameter Guidelines:\n",
    "- **n_top_features**: \n",
    "  - Small datasets (<100 samples): 50-200 features\n",
    "  - Medium datasets (100-1000 samples): 500-1000 features\n",
    "  - Large datasets (>1000 samples): 1000-2000 features\n",
    "\n",
    "- **max_dropout_rate**: \n",
    "  - Conservative: 0.3 (70% detection required)\n",
    "  - Moderate: 0.5 (50% detection required)\n",
    "  - Permissive: 0.7 (30% detection required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "### Feature Selection Methods:\n",
    "1. **select_hvg()**: Coefficient of variation-based selection\n",
    "2. **select_by_vst()**: Variance stabilizing transformation (Seurat-style)\n",
    "3. **select_by_dispersion()**: Normalized dispersion-based selection\n",
    "4. **select_by_dropout()**: Filter by missing/dropout rate\n",
    "5. **select_by_model_importance()**: Random forest importance\n",
    "6. **select_by_pca_loadings()**: PCA contribution-based selection\n",
    "\n",
    "### Key Concepts:\n",
    "- **Variability**: Variable features are more informative\n",
    "- **Dropout rate**: High missingness reduces reliability\n",
    "- **Mean-variance relationship**: Important for proper normalization\n",
    "- **Method selection**: Depends on data characteristics and goals\n",
    "\n",
    "### Best Practices:\n",
    "- Apply appropriate normalization before feature selection\n",
    "   - Use annotation mode (subset=False) for exploration\n",
    "   - Use subset mode (subset=True) for final filtering\n",
    "- Compare multiple methods to find robust features\n",
    "- Validate by checking impact on PCA and clustering\n",
    "\n",
    "### Next Steps:\n",
    "- **Tutorial 08**: Custom Analysis Pipeline\n",
    "- Apply selected features to clustering and differential expression\n",
    "- Explore pathway enrichment on selected features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

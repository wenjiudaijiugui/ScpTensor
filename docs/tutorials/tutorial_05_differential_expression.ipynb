{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 05: Differential Expression Analysis\n",
    "\n",
    "This tutorial covers differential expression (DE) analysis for identifying proteins/peptides that differ significantly between experimental groups.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand different statistical tests for differential expression\n",
    "- Perform two-group comparisons (t-test, Mann-Whitney, permutation test)\n",
    "- Perform multi-group comparisons (ANOVA, Kruskal-Wallis)\n",
    "- Apply paired sample analysis for matched samples\n",
    "- Adjust p-values for multiple testing (FDR correction)\n",
    "- Visualize DE results using volcano plots and heatmaps\n",
    "- Interpret effect sizes and fold changes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import required libraries and load a dataset suitable for DE analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Apply SciencePlots style\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "\n",
    "# Import ScpTensor\n",
    "import scptensor\n",
    "from scptensor.datasets import load_simulated_scrnaseq_like\n",
    "from scptensor import (\n",
    "    # Differential expression methods\n",
    "    diff_expr_ttest,\n",
    "    diff_expr_paired_ttest,\n",
    "    diff_expr_mannwhitney,\n",
    "    diff_expr_anova,\n",
    "    diff_expr_kruskal,\n",
    "    diff_expr_permutation_test,\n",
    "    adjust_fdr,\n",
    "    check_homoscedasticity,\n",
    "    # Visualization\n",
    "    volcano,\n",
    "    heatmap,\n",
    "    # Normalization\n",
    "    norm_log,\n",
    ")\n",
    "\n",
    "print(f\"ScpTensor version: {scptensor.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "For DE analysis, we need a dataset with clearly defined groups (e.g., treatment vs control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with multiple cell types (simulating treatment groups)\n",
    "container = load_simulated_scrnaseq_like()\n",
    "\n",
    "print(f\"Dataset loaded: {container}\")\n",
    "print(f\"Samples: {container.n_samples}\")\n",
    "print(f\"Features: {container.assays['proteins'].n_features}\")\n",
    "\n",
    "# Check available groups\n",
    "print(\"\\nCell type distribution:\")\n",
    "print(container.obs.group_by(\"cell_type\").count().sort(\"cell_type\"))\n",
    "\n",
    "print(\"\\nBatch distribution:\")\n",
    "print(container.obs.group_by(\"batch\").count().sort(\"batch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocessing: Log Normalization\n",
    "\n",
    "Before DE analysis, apply log normalization to stabilize variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log normalization\n",
    "container = norm_log(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"raw\",\n",
    "    new_layer_name=\"log\",\n",
    "    base=2.0,\n",
    "    offset=1.0,\n",
    ")\n",
    "\n",
    "print(\"Log normalization completed.\")\n",
    "print(f\"Available layers: {list(container.assays['proteins'].layers.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Two-Group Comparison: T-Test\n",
    "\n",
    "The t-test is the most common method for comparing two groups. ScpTensor implements **Welch's t-test** by default, which does not assume equal variances between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform t-test comparing two cell types\n",
    "result_ttest = diff_expr_ttest(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    group_col=\"cell_type\",\n",
    "    group1=\"T-cell\",\n",
    "    group2=\"B-cell\",\n",
    "    layer_name=\"log\",\n",
    "    equal_var=False,  # Welch's t-test (recommended)\n",
    "    missing_strategy=\"ignore\",\n",
    ")\n",
    "\n",
    "print(\"T-test results summary:\")\n",
    "print(f\"  Method: {result_ttest.method}\")\n",
    "print(f\"  Features tested: {len(result_ttest.feature_ids)}\")\n",
    "print(f\"  Significant features (FDR < 0.05): {(result_ttest.p_values_adj < 0.05).sum()}\")\n",
    "print(f\"  Significant with |log2FC| > 1: {((result_ttest.p_values_adj < 0.05) & (np.abs(result_ttest.log2_fc) > 1)).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Exploring T-Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = result_ttest.to_dataframe()\n",
    "\n",
    "print(\"Top 10 significant features:\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.filter(pl.col(\"p_value_adj\") < 0.05).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Volcano Plot\n",
    "\n",
    "A volcano plot visualizes the relationship between fold change and statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create volcano plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Prepare data\n",
    "log2fc = result_ttest.log2_fc\n",
    "neg_log_pval = -np.log10(result_ttest.p_values_adj)\n",
    "\n",
    "# Define significance thresholds\n",
    "pval_threshold = 0.05\n",
    "fc_threshold = 1.0\n",
    "\n",
    "# Color points based on significance\n",
    "colors = np.full(len(log2fc), 'gray', dtype=object)\n",
    "is_sig = result_ttest.p_values_adj < pval_threshold\n",
    "colors[is_sig & (log2fc > fc_threshold)] = 'red'  # Up-regulated\n",
    "colors[is_sig & (log2fc < -fc_threshold)] = 'blue'  # Down-regulated\n",
    "\n",
    "# Plot scatter\n",
    "ax.scatter(log2fc, neg_log_pval, c=colors, alpha=0.6, s=20)\n",
    "\n",
    "# Add threshold lines\n",
    "ax.axhline(-np.log10(pval_threshold), color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(fc_threshold, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.axvline(-fc_threshold, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel('log2 Fold Change (T-cell vs B-cell)')\n",
    "ax.set_ylabel('-log10 Adjusted P-value')\n",
    "ax.set_title('Volcano Plot: T-cell vs B-cell')\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', label=f'Up-regulated ({(is_sig & (log2fc > fc_threshold)).sum()})'),\n",
    "    Patch(facecolor='blue', label=f'Down-regulated ({(is_sig & (log2fc < -fc_threshold)).sum()})'),\n",
    "    Patch(facecolor='gray', label=f'Not significant ({(~is_sig).sum()}')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/volcano_ttest.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Volcano plot saved to: tutorial_output/volcano_ttest.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Effect Size Interpretation\n",
    "\n",
    "**Cohen's d** measures the standardized difference between groups:\n",
    "- |d| < 0.2: Small effect\n",
    "- |d| < 0.5: Medium effect\n",
    "- |d| >= 0.8: Large effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze effect sizes\n",
    "effect_sizes = result_ttest.effect_sizes\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of effect sizes\n",
    "valid_es = effect_sizes[~np.isnan(effect_sizes)]\n",
    "axes[0].hist(valid_es, bins=50, edgecolor='black', color='steelblue')\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0].axvline(0.2, color='orange', linestyle='--', linewidth=0.5, label='Small effect')\n",
    "axes[0].axvline(0.5, color='orange', linestyle='--', linewidth=0.5, label='Medium effect')\n",
    "axes[0].axvline(0.8, color='orange', linestyle='--', linewidth=0.5, label='Large effect')\n",
    "axes[0].set_xlabel(\"Cohen's d\")\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(\"Distribution of Effect Sizes\")\n",
    "\n",
    "# Effect size vs significance\n",
    "colors = np.full(len(log2fc), 'gray', dtype=object)\n",
    "is_sig = result_ttest.p_values_adj < 0.05\n",
    "colors[is_sig] = 'red'\n",
    "\n",
    "axes[1].scatter(effect_sizes, -np.log10(result_ttest.p_values_adj), c=colors, alpha=0.5, s=15)\n",
    "axes[1].axhline(-np.log10(0.05), color='black', linestyle='--', linewidth=0.5)\n",
    "axes[1].axvline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[1].set_xlabel(\"Cohen's d (Effect Size)\")\n",
    "axes[1].set_ylabel('-log10 Adjusted P-value')\n",
    "axes[1].set_title('Effect Size vs Significance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/effect_size_analysis.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Effect size analysis saved to: tutorial_output/effect_size_analysis.png\")\n",
    "print(f\"\\nEffect size summary:\")\n",
    "print(f\"  Large effects (|d| >= 0.8): {(np.abs(effect_sizes) >= 0.8).sum()}\")\n",
    "print(f\"  Medium effects (0.5 <= |d| < 0.8): {((np.abs(effect_sizes) >= 0.5) & (np.abs(effect_sizes) < 0.8)).sum()}\")\n",
    "print(f\"  Small effects (0.2 <= |d| < 0.5): {((np.abs(effect_sizes) >= 0.2) & (np.abs(effect_sizes) < 0.5)).sum()}\")\n",
    "print(f\"  Negligible effects (|d| < 0.2): {(np.abs(effect_sizes) < 0.2).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Non-Parametric Tests\n",
    "\n",
    "When data doesn't meet normality assumptions, use non-parametric tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Mann-Whitney U Test\n",
    "\n",
    "A non-parametric test that doesn't assume normality. Tests whether samples from one group tend to have higher values than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Mann-Whitney U test\n",
    "result_mw = diff_expr_mannwhitney(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    group_col=\"cell_type\",\n",
    "    group1=\"T-cell\",\n",
    "    group2=\"B-cell\",\n",
    "    layer_name=\"log\",\n",
    "    alternative=\"two-sided\",\n",
    "    missing_strategy=\"ignore\",\n",
    ")\n",
    "\n",
    "print(\"Mann-Whitney U test results:\")\n",
    "print(f\"  Features tested: {len(result_mw.feature_ids)}\")\n",
    "print(f\"  Significant features (FDR < 0.05): {(result_mw.p_values_adj < 0.05).sum()}\")\n",
    "print(f\"  Significant with |log2FC| > 1: {((result_mw.p_values_adj < 0.05) & (np.abs(result_mw.log2_fc) > 1)).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Permutation Test\n",
    "\n",
    "A resampling-based test that makes no distributional assumptions. Useful for small sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform permutation test\n",
    "# Note: n_permutations=100 for speed; use 1000+ for real analysis\n",
    "result_perm = diff_expr_permutation_test(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    group_col=\"cell_type\",\n",
    "    group1=\"T-cell\",\n",
    "    group2=\"B-cell\",\n",
    "    layer_name=\"log\",\n",
    "    n_permutations=500,  # Increase for higher precision\n",
    "    alternative=\"two-sided\",\n",
    "    missing_strategy=\"ignore\",\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "print(\"Permutation test results:\")\n",
    "print(f\"  Features tested: {len(result_perm.feature_ids)}\")\n",
    "print(f\"  Significant features (FDR < 0.05): {(result_perm.p_values_adj < 0.05).sum()}\")\n",
    "print(f\"  Significant with |log2FC| > 1: {((result_perm.p_values_adj < 0.05) & (np.abs(result_perm.log2_fc) > 1)).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Comparing Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare p-values from different tests\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# T-test vs Mann-Whitney\n",
    "valid_mask = ~np.isnan(result_ttest.p_values_adj) & ~np.isnan(result_mw.p_values_adj)\n",
    "axes[0].scatter(result_ttest.p_values_adj[valid_mask], \n",
    "            result_mw.p_values_adj[valid_mask], \n",
    "            alpha=0.5, s=10)\n",
    "axes[0].plot([0, 1], [0, 1], 'r--', linewidth=1)\n",
    "axes[0].set_xlabel('T-test Adjusted P-value')\n",
    "axes[0].set_ylabel('Mann-Whitney Adjusted P-value')\n",
    "axes[0].set_title('T-test vs Mann-Whitney P-values')\n",
    "\n",
    "# T-test vs Permutation\n",
    "valid_mask2 = ~np.isnan(result_ttest.p_values_adj) & ~np.isnan(result_perm.p_values_adj)\n",
    "axes[1].scatter(result_ttest.p_values_adj[valid_mask2], \n",
    "            result_perm.p_values_adj[valid_mask2], \n",
    "            alpha=0.5, s=10)\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', linewidth=1)\n",
    "axes[1].set_xlabel('T-test Adjusted P-value')\n",
    "axes[1].set_ylabel('Permutation Adjusted P-value')\n",
    "axes[1].set_title('T-test vs Permutation P-values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/test_comparison.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Test comparison saved to: tutorial_output/test_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Group Comparison: ANOVA\n",
    "\n",
    "When comparing more than two groups, use ANOVA (parametric) or Kruskal-Wallis (non-parametric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-way ANOVA\n",
    "result_anova = diff_expr_anova(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    group_col=\"cell_type\",\n",
    "    layer_name=\"log\",\n",
    "    missing_strategy=\"ignore\",\n",
    ")\n",
    "\n",
    "print(\"ANOVA results:\")\n",
    "print(f\"  Number of groups: {result_anova.params['n_groups']}\")\n",
    "print(f\"  Groups: {result_anova.params['groups']}\")\n",
    "print(f\"  Features tested: {len(result_anova.feature_ids)}\")\n",
    "print(f\"  Significant features (FDR < 0.05): {(result_anova.p_values_adj < 0.05).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Visualizing ANOVA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA results visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# F-statistic distribution\n",
    "f_stats = result_anova.test_statistics[~np.isnan(result_anova.test_statistics)]\n",
    "axes[0].hist(f_stats, bins=50, edgecolor='black', color='lightgreen')\n",
    "axes[0].set_xlabel('F-statistic')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of F-statistics')\n",
    "\n",
    "# P-value distribution\n",
    "pvals = result_anova.p_values_adj[~np.isnan(result_anova.p_values_adj)]\n",
    "axes[1].hist(pvals, bins=50, edgecolor='black', color='coral')\n",
    "axes[1].axvline(0.05, color='red', linestyle='--', linewidth=1)\n",
    "axes[1].set_xlabel('Adjusted P-value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Adjusted P-values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/anova_results.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"ANOVA results saved to: tutorial_output/anova_results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Kruskal-Wallis Test (Non-Parametric ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Kruskal-Wallis test\n",
    "result_kw = diff_expr_kruskal(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    group_col=\"cell_type\",\n",
    "    layer_name=\"log\",\n",
    "    missing_strategy=\"ignore\",\n",
    ")\n",
    "\n",
    "print(\"Kruskal-Wallis results:\")\n",
    "print(f\"  Features tested: {len(result_kw.feature_ids)}\")\n",
    "print(f\"  Significant features (FDR < 0.05): {(result_kw.p_values_adj < 0.05).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Paired Sample Analysis\n",
    "\n",
    "For paired/matched samples (e.g., before-after treatment), use the paired t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate paired data by creating a patient_id column\n",
    "# In real data, this would come from your experimental design\n",
    "import polars as pl\n",
    "\n",
    "# Create simulated pairs (same number of samples in each batch)\n",
    "n_samples = container.n_samples\n",
    "n_pairs = n_samples // 2\n",
    "\n",
    "# Add pair_id to obs\n",
    "pair_ids = []\n",
    "for i in range(n_samples):\n",
    "    pair_ids.append(f\"Pair_{i % n_pairs}\")\n",
    "\n",
    "container.obs = container.obs.with_columns(\n",
    "    pl.Series(\"pair_id\", pair_ids)\n",
    ")\n",
    "\n",
    "print(\"Added pair_id column to obs for paired analysis.\")\n",
    "print(f\"Number of unique pairs: {len(container.obs['pair_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform paired t-test (comparing batches as paired samples)\n",
    "try:\n",
    "    result_paired = diff_expr_paired_ttest(\n",
    "        container=container,\n",
    "        assay_name=\"proteins\",\n",
    "        group_col=\"batch\",\n",
    "        pair_id_col=\"pair_id\",\n",
    "        layer_name=\"log\",\n",
    "        missing_strategy=\"ignore\",\n",
    "    )\n",
    "    \n",
    "    print(\"Paired t-test results:\")\n",
    "    print(f\"  Number of pairs: {result_paired.params['n_pairs']}\")\n",
    "    print(f\"  Features tested: {len(result_paired.feature_ids)}\")\n",
    "    print(f\"  Significant features (FDR < 0.05): {(result_paired.p_values_adj < 0.05).sum()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Paired t-test not available: {e}\")\n",
    "    print(\"(Paired test requires complete pairs across all groups)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiple Testing Correction\n",
    "\n",
    "When testing many features, control the false discovery rate (FDR) using p-value adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different correction methods\n",
    "from scptensor.diff_expr import adjust_fdr\n",
    "\n",
    "# Get raw p-values from t-test\n",
    "raw_pvals = result_ttest.p_values\n",
    "\n",
    "# Apply different corrections\n",
    "methods = ['bh', 'by', 'bonferroni', 'holm', 'hommel']\n",
    "corrections = {}\n",
    "\n",
    "for method in methods:\n",
    "    corrections[method] = adjust_fdr(raw_pvals, method=method)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Count significant features at different thresholds\n",
    "alphas = [0.01, 0.05, 0.1, 0.2]\n",
    "x = np.arange(len(alphas))\n",
    "width = 0.15\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    counts = [(corrections[method] < alpha).sum() for alpha in alphas]\n",
    "    axes[0].bar(x + i * width, counts, width, label=method.upper())\n",
    "\n",
    "axes[0].set_xlabel('FDR Threshold')\n",
    "axes[0].set_ylabel('Number of Significant Features')\n",
    "axes[0].set_xticks(x + width * 2)\n",
    "axes[0].set_xticklabels([str(a) for a in alphas])\n",
    "axes[0].set_title('Significant Features by Correction Method')\n",
    "axes[0].legend()\n",
    "\n",
    "# P-value inflation plot\n",
    "sorted_pvals = np.sort(raw_pvals[~np.isnan(raw_pvals)])\n",
    "expected = np.linspace(0, 1, len(sorted_pvals))\n",
    "\n",
    "axes[1].scatter(expected, sorted_pvals, s=5, alpha=0.5, label='Raw p-values')\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', linewidth=1, label='Expected (null)')\n",
    "axes[1].set_xlabel('Expected p-value (Uniform)')\n",
    "axes[1].set_ylabel('Observed p-value')\n",
    "axes[1].set_title('P-value Inflation Plot')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/fdr_correction.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"FDR correction comparison saved to: tutorial_output/fdr_correction.png\")\n",
    "\n",
    "print(\"\\nSignificant features (FDR < 0.05) by method:\")\n",
    "for method in methods:\n",
    "    n_sig = (corrections[method] < 0.05).sum()\n",
    "    print(f\"  {method.upper():12s}: {n_sig:4d} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Homoscedasticity Testing\n",
    "\n",
    "Before using parametric tests, check if variances are equal across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for equality of variances (Levene's test)\n",
    "homo_results = check_homoscedasticity(\n",
    "    container=container,\n",
    "    assay_name=\"proteins\",\n",
    "    group_col=\"cell_type\",\n",
    "    layer_name=\"log\",\n",
    "    test_type=\"levene\",\n",
    "    center=\"median\",\n",
    ")\n",
    "\n",
    "print(\"Homoscedasticity test results (Levene's test):\")\n",
    "print(homo_results.head(10))\n",
    "\n",
    "# Count features with unequal variances\n",
    "n_hetero = (homo_results.filter(pl.col(\"p_value_adj\") < 0.05)).shape[0]\n",
    "print(f\"\\nFeatures with unequal variances (FDR < 0.05): {n_hetero}\")\n",
    "print(f\"This supports using Welch's t-test (equal_var=False) over Student's t-test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Comprehensive DE Analysis Workflow\n",
    "\n",
    "Putting it all together: a complete DE analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete workflow function\n",
    "def run_de_analysis(container, group_col, group1, group2, alpha=0.05, fc_threshold=1.0):\n",
    "    \"\"\"Run complete differential expression analysis.\"\"\"\n",
    "    \n",
    "    # Run t-test\n",
    "    result = diff_expr_ttest(\n",
    "        container=container,\n",
    "        assay_name=\"proteins\",\n",
    "        group_col=group_col,\n",
    "        group1=group1,\n",
    "        group2=group2,\n",
    "        layer_name=\"log\",\n",
    "        equal_var=False,\n",
    "    )\n",
    "    \n",
    "    # Get significant features\n",
    "    sig_df = result.get_significant(alpha=alpha, min_log2_fc=fc_threshold)\n",
    "    \n",
    "    return result, sig_df\n",
    "\n",
    "# Run analysis\n",
    "result, sig_features = run_de_analysis(\n",
    "    container, \n",
    "    group_col=\"cell_type\",\n",
    "    group1=\"T-cell\",\n",
    "    group2=\"B-cell\",\n",
    "    alpha=0.05,\n",
    "    fc_threshold=1.0\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DIFFERENTIAL EXPRESSION ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nComparison: {result.params['group1']} vs {result.params['group2']}\")\n",
    "print(f\"Method: {result.method}\")\n",
    "print(f\"Features tested: {len(result.feature_ids)}\")\n",
    "print(f\"\\nSignificant features (FDR < 0.05, |log2FC| > 1): {len(sig_features)}\")\n",
    "\n",
    "# Print top significant features\n",
    "print(\"\\nTop 10 significant features:\")\n",
    "print(sig_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Exporting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('tutorial_output', exist_ok=True)\n",
    "\n",
    "# Save full results\n",
    "full_results = result.to_dataframe()\n",
    "full_results.write_csv('tutorial_output/de_results_full.csv')\n",
    "print(\"Full results saved to: tutorial_output/de_results_full.csv\")\n",
    "\n",
    "# Save significant results only\n",
    "sig_features.write_csv('tutorial_output/de_results_significant.csv')\n",
    "print(\"Significant results saved to: tutorial_output/de_results_significant.csv\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"  Total features: {len(full_results)}\")\n",
    "print(f\"  Tested features: {full_results.filter(pl.col('p_value').is_not_null()).shape[0]}\")\n",
    "print(f\"  Significant (FDR < 0.05): {full_results.filter(pl.col('p_value_adj') < 0.05).shape[0]}\")\n",
    "print(f\"  Up-regulated: {full_results.filter((pl.col('p_value_adj') < 0.05) & (pl.col('log2_fc') > 1)).shape[0]}\")\n",
    "print(f\"  Down-regulated: {full_results.filter((pl.col('p_value_adj') < 0.05) & (pl.col('log2_fc') < -1)).shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "### Statistical Tests:\n",
    "1. **T-test (Welch's)**: Two-group comparison with unequal variance assumption\n",
    "2. **Mann-Whitney U**: Non-parametric two-group comparison\n",
    "3. **Permutation test**: Resampling-based non-parametric test\n",
    "4. **ANOVA**: Multi-group comparison (parametric)\n",
    "5. **Kruskal-Wallis**: Multi-group comparison (non-parametric)\n",
    "6. **Paired t-test**: For matched/paired samples\n",
    "\n",
    "### Key Concepts:\n",
    "- **Effect Size**: Cohen's d measures standardized difference between groups\n",
    "- **Fold Change**: Log2 fold change indicates magnitude of difference\n",
    "- **FDR Correction**: Benjamini-Hochberg (BH) controls false discovery rate\n",
    "- **Homoscedasticity**: Test equality of variances before parametric tests\n",
    "\n",
    "### Choosing a Test:\n",
    "- **Two groups, normal distribution**: Welch's t-test\n",
    "- **Two groups, non-normal**: Mann-Whitney U or permutation test\n",
    "- **Multiple groups**: ANOVA or Kruskal-Wallis\n",
    "- **Paired samples**: Paired t-test\n",
    "\n",
    "### Best Practices:\n",
    "- Always apply appropriate normalization before DE analysis\n",
    "- Check assumptions (normality, homoscedasticity) when using parametric tests\n",
    "- Use FDR correction for multiple testing\n",
    "- Consider both statistical significance (p-value) and effect size\n",
    "- Visualize results with volcano plots\n",
    "\n",
    "### Next Steps:\n",
    "- **Tutorial 06**: Advanced Quality Control\n",
    "- **Tutorial 07**: Feature Selection\n",
    "- **Tutorial 08**: Custom Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

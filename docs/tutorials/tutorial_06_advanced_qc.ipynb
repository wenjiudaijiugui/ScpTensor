{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 06: Advanced Quality Control Analysis\n",
    "\n",
    "This tutorial covers advanced quality control (QC) techniques for single-cell proteomics data, building upon the basic QC methods introduced in Tutorial 02.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand sensitivity analysis and feature saturation\n",
    "- Analyze missing value types using mask matrices\n",
    "- Compute and interpret coefficient of variation (CV)\n",
    "- Detect contaminants and doublets\n",
    "- Create comprehensive QC visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import required libraries and load an example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# Apply SciencePlots style\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "\n",
    "# Import ScpTensor\n",
    "import scptensor\n",
    "from scptensor import (\n",
    "    # Missing value analysis\n",
    "    analyze_missing_types,\n",
    "    calculate_qc_metrics,\n",
    "    compute_batch_cv,\n",
    "    compute_completeness,\n",
    "    compute_cumulative_sensitivity,\n",
    "    # Variability analysis\n",
    "    compute_cv,\n",
    "    compute_jaccard_index,\n",
    "    compute_missing_stats,\n",
    "    # Sensitivity analysis\n",
    "    compute_sensitivity,\n",
    "    # Advanced QC\n",
    "    detect_contaminants,\n",
    "    detect_doublets,\n",
    "    filter_by_cv,\n",
    "    qc_report_metrics,\n",
    "    report_missing_values,\n",
    ")\n",
    "from scptensor.datasets import load_simulated_scrnaseq_like\n",
    "\n",
    "print(f\"ScpTensor version: {scptensor.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "For this tutorial, we'll use a simulated dataset that includes batch information and realistic missing value patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulated dataset\n",
    "container = load_simulated_scrnaseq_like()\n",
    "\n",
    "print(f\"Dataset loaded: {container}\")\n",
    "print(f\"\\nSamples: {container.n_samples}\")\n",
    "print(f\"Features: {container.assays['proteins'].n_features}\")\n",
    "print(\"\\nAvailable columns in obs:\")\n",
    "print(container.obs.columns)\n",
    "print(\"\\nBatch distribution:\")\n",
    "print(container.obs[\"batch\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "```\n",
    "Dataset loaded: ScpContainer with 500 samples and 1 assay\n",
    "\n",
    "Samples: 500\n",
    "Features: 200\n",
    "\n",
    "Available columns in obs:\n",
    "['sample_id', 'batch', 'cell_type', ...]\n",
    "\n",
    "Batch distribution:\n",
    "shape: (3, 2)\n",
    "┌───────┬───────────┐\n",
    "│ batch ┆ count     │\n",
    "│ ---   ┆ ---       │\n",
    "│ str   ┆ u32       │\n",
    "╞═══════╪═══════════╡\n",
    "│ B1    ┆ 167       │\n",
    "│ B2    ┆ 167       │\n",
    "│ B3    ┆ 166       │\n",
    "└───────┴───────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Sensitivity Analysis\n",
    "\n",
    "Sensitivity analysis measures the number of features detected per sample and across the entire dataset. This is crucial for assessing data quality in single-cell proteomics where missing values are common.\n",
    "\n",
    "### 2.1 Compute Basic Sensitivity Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sensitivity metrics\n",
    "metrics = compute_sensitivity(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", detection_threshold=0.0\n",
    ")\n",
    "\n",
    "print(\"Sensitivity Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total unique features detected: {metrics.total_features}\")\n",
    "print(f\"Mean features per sample: {metrics.mean_sensitivity:.2f}\")\n",
    "print(f\"Median features per sample: {np.median(metrics.n_features_per_sample):.2f}\")\n",
    "print(f\"Min features per sample: {np.min(metrics.n_features_per_sample)}\")\n",
    "print(f\"Max features per sample: {np.max(metrics.n_features_per_sample)}\")\n",
    "print(f\"\\nMean completeness: {np.mean(metrics.completeness_per_sample):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compute Completeness\n",
    "\n",
    "Completeness is the proportion of features detected in each sample. Low completeness indicates poor quality samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute completeness per sample\n",
    "completeness = compute_completeness(container, assay_name=\"proteins\", layer_name=\"raw\")\n",
    "\n",
    "# Identify low completeness samples\n",
    "low_completeness_threshold = 0.5  # 50% completeness\n",
    "low_comp_samples = np.where(completeness < low_completeness_threshold)[0]\n",
    "\n",
    "print(f\"Samples with completeness < {low_completeness_threshold * 100}%: {len(low_comp_samples)}\")\n",
    "print(f\"Percentage: {len(low_comp_samples) / len(completeness) * 100:.2f}%\")\n",
    "\n",
    "# Plot completeness distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.hist(completeness, bins=30, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "ax.axvline(\n",
    "    low_completeness_threshold,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Threshold: {low_completeness_threshold * 100}%\",\n",
    ")\n",
    "ax.axvline(\n",
    "    np.mean(completeness),\n",
    "    color=\"green\",\n",
    "    linestyle=\"-.\",\n",
    "    label=f\"Mean: {np.mean(completeness) * 100:.1f}%\",\n",
    ")\n",
    "ax.set_xlabel(\"Completeness (proportion of detected features)\")\n",
    "ax.set_ylabel(\"Number of Samples\")\n",
    "ax.set_title(\"Sample Completeness Distribution\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/completeness_distribution.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot saved to: tutorial_output/completeness_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cumulative Sensitivity (Feature Saturation)\n",
    "\n",
    "Cumulative sensitivity analysis shows how the number of unique features detected increases as more samples are included. This helps assess whether the feature space has been adequately sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cumulative sensitivity\n",
    "cumulative_result = compute_cumulative_sensitivity(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", n_steps=20, seed=42\n",
    ")\n",
    "\n",
    "print(\"Cumulative Sensitivity Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total features in dataset: {container.assays['proteins'].n_features}\")\n",
    "print(f\"Total unique detected: {cumulative_result.cumulative_features[-1]}\")\n",
    "if cumulative_result.saturation_point:\n",
    "    print(f\"Estimated saturation at: {cumulative_result.saturation_point} samples\")\n",
    "else:\n",
    "    print(\"Saturation not reached within sample size\")\n",
    "\n",
    "# Plot cumulative sensitivity curve\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(\n",
    "    cumulative_result.sample_sizes,\n",
    "    cumulative_result.cumulative_features,\n",
    "    marker=\"o\",\n",
    "    linewidth=2,\n",
    "    markersize=4,\n",
    ")\n",
    "ax.axhline(\n",
    "    container.assays[\"proteins\"].n_features,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Total features: {container.assays['proteins'].n_features}\",\n",
    ")\n",
    "ax.set_xlabel(\"Number of Samples\")\n",
    "ax.set_ylabel(\"Cumulative Unique Features Detected\")\n",
    "ax.set_title(\"Feature Saturation Curve\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/cumulative_sensitivity.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: tutorial_output/cumulative_sensitivity.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Jaccard Index (Sample Similarity)\n",
    "\n",
    "The Jaccard index measures the overlap of detected features between sample pairs. High similarity indicates consistent detection patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Jaccard index matrix\n",
    "jaccard = compute_jaccard_index(container, assay_name=\"proteins\", layer_name=\"raw\")\n",
    "\n",
    "# Calculate summary statistics\n",
    "n_samples = jaccard.shape[0]\n",
    "# Get upper triangle (excluding diagonal)\n",
    "upper_tri = jaccard[np.triu_indices_from(jaccard, k=1)]\n",
    "\n",
    "print(\"Jaccard Index Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean similarity: {np.mean(upper_tri):.3f}\")\n",
    "print(f\"Median similarity: {np.median(upper_tri):.3f}\")\n",
    "print(f\"Min similarity: {np.min(upper_tri):.3f}\")\n",
    "print(f\"Max similarity: {np.max(upper_tri):.3f}\")\n",
    "\n",
    "# Visualize as heatmap for a subset of samples\n",
    "n_display = min(50, n_samples)\n",
    "jaccard_subset = jaccard[:n_display, :n_display]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "im = ax.imshow(\n",
    "    jaccard_subset, cmap=\"viridis\", aspect=\"auto\", interpolation=\"nearest\", vmin=0, vmax=1\n",
    ")\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Jaccard Index\")\n",
    "ax.set_title(f\"Sample Similarity Heatmap (first {n_display} samples)\")\n",
    "ax.set_xlabel(\"Sample Index\")\n",
    "ax.set_ylabel(\"Sample Index\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/jaccard_heatmap.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: tutorial_output/jaccard_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Generate QC Report with Grouping\n",
    "\n",
    "You can generate QC reports grouped by metadata columns such as batch or cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate QC metrics grouped by batch\n",
    "container_with_qc = qc_report_metrics(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", group_by=\"batch\"\n",
    ")\n",
    "\n",
    "# View the added QC metrics\n",
    "print(\"QC metrics added to obs:\")\n",
    "print(\"=\" * 50)\n",
    "print(\n",
    "    container_with_qc.obs.select(\n",
    "        [\n",
    "            \"sample_id\",\n",
    "            \"batch\",\n",
    "            \"n_detected_features\",\n",
    "            \"completeness\",\n",
    "            \"batch_mean_features\",\n",
    "            \"batch_total_features\",\n",
    "        ]\n",
    "    ).head(10)\n",
    ")\n",
    "\n",
    "# Generate summary report by batch\n",
    "batch_report = report_missing_values(\n",
    "    container_with_qc, assay_name=\"proteins\", layer_name=\"raw\", by=\"batch\"\n",
    ")\n",
    "\n",
    "print(\"\\nBatch-wise QC Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(batch_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Missing Value Analysis\n",
    "\n",
    "ScpTensor tracks different types of missing values using mask codes:\n",
    "- **VALID (0)**: Detected values\n",
    "- **MBR (1)**: Missing Between Runs\n",
    "- **LOD (2)**: Below Limit of Detection\n",
    "- **FILTERED (3)**: Removed by QC\n",
    "- **IMPUTED (5)**: Filled by imputation\n",
    "\n",
    "### 3.1 Analyze Missing Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing types based on mask matrix\n",
    "container_analyzed = analyze_missing_types(container, assay_name=\"proteins\", layer_name=\"raw\")\n",
    "\n",
    "# View mask statistics in var\n",
    "var = container_analyzed.assays[\"proteins\"].var\n",
    "\n",
    "print(\"Missing Type Analysis (first 10 features):\")\n",
    "print(\"=\" * 60)\n",
    "print(\n",
    "    var.select(\n",
    "        [\n",
    "            \"feature_id\",\n",
    "            \"mask_valid_count\",\n",
    "            \"mask_mbr_count\",\n",
    "            \"mask_lod_count\",\n",
    "            \"mask_valid_rate\",\n",
    "            \"mask_missing_rate\",\n",
    "        ]\n",
    "    ).head(10)\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary across all features:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean valid rate: {var['mask_valid_rate'].mean():.3f}\")\n",
    "print(f\"Mean missing rate: {var['mask_missing_rate'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compute Comprehensive Missing Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute comprehensive missing value statistics\n",
    "missing_report = compute_missing_stats(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", high_missing_threshold=0.5\n",
    ")\n",
    "\n",
    "print(\"Missing Value Statistics Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total missing rate: {missing_report.total_missing_rate:.2%}\")\n",
    "print(f\"Valid rate: {missing_report.valid_rate:.2%}\")\n",
    "print(f\"MBR rate: {missing_report.mbr_rate:.2%}\")\n",
    "print(f\"LOD rate: {missing_report.lod_rate:.2%}\")\n",
    "print(f\"Imputed rate: {missing_report.imputed_rate:.2%}\")\n",
    "print(\n",
    "    f\"\\nStructural missing features (100% missing): {len(missing_report.structural_missing_features)}\"\n",
    ")\n",
    "print(f\"Samples with high missing rate (>50%): {len(missing_report.samples_with_high_missing)}\")\n",
    "\n",
    "# Visualize missing value type distribution\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Mask type counts\n",
    "mask_types = [\"VALID\", \"MBR\", \"LOD\", \"FILTERED\", \"IMPUTED\"]\n",
    "mask_codes = [0, 1, 2, 3, 5]\n",
    "colors = [\"#2ca02c\", \"#ffdd57\", \"#ff9f40\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "# Get actual counts from the mask matrix\n",
    "M = container.assays[\"proteins\"].layers[\"raw\"].M\n",
    "if hasattr(M, \"toarray\"):\n",
    "    M = M.toarray()\n",
    "\n",
    "type_counts = []\n",
    "type_labels = []\n",
    "type_colors = []\n",
    "\n",
    "for code, label, color in zip(mask_codes, mask_types, colors, strict=False):\n",
    "    count = np.sum(code == M)\n",
    "    if count > 0:\n",
    "        type_counts.append(count)\n",
    "        type_labels.append(f\"{label}\\n({code})\")\n",
    "        type_colors.append(color)\n",
    "\n",
    "# Create bar plot\n",
    "bars = ax.bar(range(len(type_counts)), type_counts, color=type_colors, edgecolor=\"black\", alpha=0.8)\n",
    "ax.set_xticks(range(len(type_labels)))\n",
    "ax.set_xticklabels(type_labels)\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Missing Value Type Distribution\")\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, type_counts, strict=False):\n",
    "    height = bar.get_height()\n",
    "    pct = count / M.size * 100\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height,\n",
    "        f\"{count}\\n({pct:.1f}%)\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/missing_type_distribution.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: tutorial_output/missing_type_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Missing Value Report by Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate missing value report by batch\n",
    "missing_by_batch = report_missing_values(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", by=\"batch\"\n",
    ")\n",
    "\n",
    "print(\"Missing Value Report by Batch:\")\n",
    "print(\"=\" * 60)\n",
    "print(missing_by_batch)\n",
    "\n",
    "# Compare batches\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Extract data for plotting\n",
    "batches = missing_by_batch[\"group\"].to_numpy()\n",
    "local_sensitivity = missing_by_batch[\"LocalSensitivityMean\"].to_numpy()\n",
    "total_sensitivity = missing_by_batch[\"TotalSensitivity\"].to_numpy()\n",
    "completeness = missing_by_batch[\"Completeness\"].to_numpy()\n",
    "\n",
    "# Local sensitivity\n",
    "axes[0].bar(batches, local_sensitivity, color=\"steelblue\", edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].set_ylabel(\"Mean Detected Features\")\n",
    "axes[0].set_title(\"Local Sensitivity by Batch\")\n",
    "axes[0].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Total sensitivity\n",
    "axes[1].bar(batches, total_sensitivity, color=\"coral\", edgecolor=\"black\", alpha=0.7)\n",
    "axes[1].set_ylabel(\"Total Unique Features\")\n",
    "axes[1].set_title(\"Total Sensitivity by Batch\")\n",
    "axes[1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Completeness\n",
    "axes[2].bar(batches, completeness, color=\"seagreen\", edgecolor=\"black\", alpha=0.7)\n",
    "axes[2].set_ylabel(\"Completeness\")\n",
    "axes[2].set_title(\"Completeness by Batch\")\n",
    "axes[2].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/batch_missing_comparison.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: tutorial_output/batch_missing_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Variability Analysis (Coefficient of Variation)\n",
    "\n",
    "The coefficient of variation (CV) measures the relative variability of each feature. Features with high CV may indicate poor measurement quality or true biological heterogeneity.\n",
    "\n",
    "### 4.1 Compute Feature CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CV for all features\n",
    "cv_report = compute_cv(container, assay_name=\"proteins\", layer_name=\"raw\", min_mean=1e-6)\n",
    "\n",
    "print(\"Coefficient of Variation Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean CV: {cv_report.mean_cv:.3f}\")\n",
    "print(f\"Median CV: {cv_report.median_cv:.3f}\")\n",
    "print(f\"Min CV: {np.min(cv_report.feature_cv):.3f}\")\n",
    "print(f\"Max CV: {np.max(cv_report.feature_cv):.3f}\")\n",
    "\n",
    "# Define CV thresholds\n",
    "low_cv_threshold = 0.1\n",
    "medium_cv_threshold = 0.3\n",
    "high_cv_threshold = 0.5\n",
    "\n",
    "n_low = np.sum(cv_report.feature_cv < low_cv_threshold)\n",
    "n_medium = np.sum(\n",
    "    (cv_report.feature_cv >= low_cv_threshold) & (cv_report.feature_cv < medium_cv_threshold)\n",
    ")\n",
    "n_high = np.sum(cv_report.feature_cv >= medium_cv_threshold)\n",
    "\n",
    "print(\n",
    "    f\"\\nFeatures with low CV (<{low_cv_threshold}): {n_low} ({n_low / len(cv_report.feature_cv) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Features with medium CV ({low_cv_threshold}-{medium_cv_threshold}): {n_medium} ({n_medium / len(cv_report.feature_cv) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"Features with high CV (>={medium_cv_threshold}): {n_high} ({n_high / len(cv_report.feature_cv) * 100:.1f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 CV Distribution by Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CV by batch\n",
    "cv_report_batched = compute_cv(container, assay_name=\"proteins\", layer_name=\"raw\", group_by=\"batch\")\n",
    "\n",
    "print(\"CV Statistics by Batch:\")\n",
    "print(\"=\" * 60)\n",
    "if cv_report_batched.cv_by_group:\n",
    "    for group, cv_values in cv_report_batched.cv_by_group.items():\n",
    "        print(\n",
    "            f\"{group}: Mean CV = {np.mean(cv_values):.3f}, Median CV = {np.median(cv_values):.3f}\"\n",
    "        )\n",
    "\n",
    "# Plot CV distributions by batch\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "if cv_report_batched.cv_by_group:\n",
    "    # Prepare data for box plot\n",
    "    groups = list(cv_report_batched.cv_by_group.keys())\n",
    "    data_to_plot = [cv_report_batched.cv_by_group[g] for g in groups]\n",
    "\n",
    "    bp = ax.boxplot(data_to_plot, labels=groups, patch_artist=True)\n",
    "\n",
    "    # Color the boxes\n",
    "    colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]\n",
    "    for patch, color in zip(bp[\"boxes\"], colors[: len(groups)], strict=False):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.6)\n",
    "\n",
    "    ax.set_ylabel(\"Coefficient of Variation\")\n",
    "    ax.set_title(\"CV Distribution by Batch\")\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/cv_by_batch.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: tutorial_output/cv_by_batch.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Batch CV Analysis\n",
    "\n",
    "Compare within-batch variability to between-batch variability to detect batch effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute batch CV statistics\n",
    "batch_cv_report = compute_batch_cv(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", batch_col=\"batch\", high_cv_threshold=0.3\n",
    ")\n",
    "\n",
    "print(\"Batch CV Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Within-batch CV by batch:\")\n",
    "if batch_cv_report.within_batch_cv:\n",
    "    for batch, cv_val in batch_cv_report.within_batch_cv.items():\n",
    "        print(f\"  {batch}: {cv_val:.3f}\")\n",
    "print(f\"\\nBetween-batch CV: {batch_cv_report.between_batch_cv:.3f}\")\n",
    "print(f\"High CV features: {len(batch_cv_report.high_cv_features)}\")\n",
    "\n",
    "# Assess batch effect\n",
    "if batch_cv_report.within_batch_cv:\n",
    "    within_mean = np.mean(list(batch_cv_report.within_batch_cv.values()))\n",
    "    ratio = batch_cv_report.between_batch_cv / within_mean if within_mean > 0 else np.nan\n",
    "    print(f\"\\nBatch effect ratio (between/within): {ratio:.2f}\")\n",
    "    if ratio > 1.5:\n",
    "        print(\"Assessment: High batch effect detected\")\n",
    "    elif ratio > 1.1:\n",
    "        print(\"Assessment: Moderate batch effect detected\")\n",
    "    else:\n",
    "        print(\"Assessment: Low batch effect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Filter Features by CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter features by CV threshold\n",
    "cv_threshold = 0.5\n",
    "container_filtered = filter_by_cv(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer_name=\"raw\",\n",
    "    cv_threshold=cv_threshold,\n",
    "    keep_filtered=False,  # Remove high CV features\n",
    ")\n",
    "\n",
    "print(f\"Before CV filtering: {container.assays['proteins'].n_features} features\")\n",
    "print(f\"After CV filtering: {container_filtered.assays['proteins'].n_features} features\")\n",
    "print(\n",
    "    f\"Features removed: {container.assays['proteins'].n_features - container_filtered.assays['proteins'].n_features}\"\n",
    ")\n",
    "\n",
    "# Alternative: keep all features but mark filtered ones\n",
    "container_marked = filter_by_cv(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer_name=\"raw\",\n",
    "    cv_threshold=cv_threshold,\n",
    "    keep_filtered=True,  # Keep all, add filter column\n",
    ")\n",
    "\n",
    "# View filter status\n",
    "var_marked = container_marked.assays[\"proteins\"].var\n",
    "n_filtered = var_marked[\"cv_filtered\"].sum()\n",
    "print(f\"\\nFeatures marked as high CV (>): {n_filtered}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Advanced Detection Methods\n",
    "\n",
    "### 5.1 Contaminant Detection\n",
    "\n",
    "Detect common contaminant proteins in proteomics data (e.g., keratins, trypsin, albumin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect contaminants\n",
    "container_with_contaminants = detect_contaminants(\n",
    "    container, assay_name=\"proteins\", layer_name=\"raw\", min_prevalence=3\n",
    ")\n",
    "\n",
    "# Check for detected contaminants\n",
    "var = container_with_contaminants.assays[\"proteins\"].var\n",
    "contaminants = var.filter(pl.col(\"is_contaminant\") == True)\n",
    "\n",
    "print(f\"Detected {len(contaminants)} contaminant proteins\")\n",
    "if len(contaminants) > 0:\n",
    "    print(\"\\nContaminant list:\")\n",
    "    print(contaminants.select([\"feature_id\", \"contaminant_prevalence\"]).head(10))\n",
    "\n",
    "# View sample-level contaminant statistics\n",
    "print(\"\\nSample contaminant content:\")\n",
    "print(\n",
    "    container_with_contaminants.obs.select(\n",
    "        [\"sample_id\", \"contaminant_content\", \"contaminant_ratio\"]\n",
    "    ).head(10)\n",
    ")\n",
    "\n",
    "# Visualize contaminant distribution\n",
    "if len(contaminants) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Contaminant ratio per sample\n",
    "    contaminant_ratio = container_with_contaminants.obs[\"contaminant_ratio\"].to_numpy()\n",
    "    axes[0].hist(contaminant_ratio, bins=30, edgecolor=\"black\", alpha=0.7, color=\"coral\")\n",
    "    axes[0].set_xlabel(\"Contaminant Ratio\")\n",
    "    axes[0].set_ylabel(\"Number of Samples\")\n",
    "    axes[0].set_title(\"Sample Contaminant Distribution\")\n",
    "    axes[0].axvline(\n",
    "        np.mean(contaminant_ratio),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mean: {np.mean(contaminant_ratio):.3f}\",\n",
    "    )\n",
    "    axes[0].legend()\n",
    "\n",
    "    # High contaminant samples\n",
    "    high_contam_threshold = 0.05  # 5%\n",
    "    n_high_contam = np.sum(contaminant_ratio > high_contam_threshold)\n",
    "    axes[1].bar(\n",
    "        [\"All samples\", f\"High (> {high_contam_threshold * 100}%)\"],\n",
    "        [len(contaminant_ratio), n_high_contam],\n",
    "        color=[\"steelblue\", \"red\"],\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "    axes[1].set_ylabel(\"Number of Samples\")\n",
    "    axes[1].set_title(\"High Contaminant Samples\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"tutorial_output/contaminant_analysis.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nPlot saved to: tutorial_output/contaminant_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Doublet Detection\n",
    "\n",
    "Detect potential doublets (samples containing material from multiple cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect doublets using KNN method\n",
    "container_with_doublets = detect_doublets(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    layer_name=\"raw\",\n",
    "    method=\"knn\",  # Options: 'knn', 'isolation', 'hybrid'\n",
    "    n_neighbors=15,\n",
    "    expected_doublet_rate=0.1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# View doublet detection results\n",
    "n_doublets = container_with_doublets.obs[\"is_doublet\"].sum()\n",
    "doublet_rate = n_doublets / container_with_doublets.n_samples * 100\n",
    "\n",
    "print(\"Doublet Detection Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Detected doublets: {n_doublets}\")\n",
    "print(f\"Doublet rate: {doublet_rate:.2f}%\")\n",
    "print(f\"Expected rate: {0.1 * 100:.1f}%\")\n",
    "\n",
    "# Doublet score statistics\n",
    "doublet_scores = container_with_doublets.obs[\"doublet_score\"].to_numpy()\n",
    "print(\"\\nDoublet score statistics:\")\n",
    "print(f\"  Mean: {np.mean(doublet_scores):.3f}\")\n",
    "print(f\"  Median: {np.median(doublet_scores):.3f}\")\n",
    "print(f\"  Min: {np.min(doublet_scores):.3f}\")\n",
    "print(f\"  Max: {np.max(doublet_scores):.3f}\")\n",
    "\n",
    "# Visualize doublet scores\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Score distribution\n",
    "axes[0].hist(doublet_scores, bins=30, edgecolor=\"black\", alpha=0.7)\n",
    "axes[0].axvline(\n",
    "    doublet_scores[np.where(container_with_doublets.obs[\"is_doublet\"].to_numpy())[0]].mean()\n",
    "    if n_doublets > 0\n",
    "    else 0,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Doublet mean\" if n_doublets > 0 else \"\",\n",
    ")\n",
    "axes[0].set_xlabel(\"Doublet Score\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].set_title(\"Doublet Score Distribution\")\n",
    "if n_doublets > 0:\n",
    "    axes[0].legend()\n",
    "\n",
    "# Score by batch\n",
    "if \"batch\" in container_with_doublets.obs.columns:\n",
    "    batches = container_with_doublets.obs[\"batch\"].unique().to_list()\n",
    "    batch_scores = [\n",
    "        container_with_doublets.obs.filter(pl.col(\"batch\") == b)[\"doublet_score\"].to_numpy()\n",
    "        for b in batches\n",
    "    ]\n",
    "\n",
    "    bp = axes[1].boxplot(batch_scores, labels=batches, patch_artist=True)\n",
    "    for patch in bp[\"boxes\"]:\n",
    "        patch.set_facecolor(\"lightblue\")\n",
    "        patch.set_alpha(0.6)\n",
    "    axes[1].set_ylabel(\"Doublet Score\")\n",
    "    axes[1].set_title(\"Doublet Score by Batch\")\n",
    "    axes[1].grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tutorial_output/doublet_detection.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPlot saved to: tutorial_output/doublet_detection.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. QC Visualization Summary\n",
    "\n",
    "Create a comprehensive QC summary figure combining multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate comprehensive QC metrics\n",
    "container_qc = calculate_qc_metrics(container, assay_name=\"proteins\", layer_name=\"raw\")\n",
    "\n",
    "# Create comprehensive QC summary\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Panel 1: Missing rate per sample\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "missing_rate = container_qc.obs[\"missing_rate\"].to_numpy()\n",
    "ax1.hist(missing_rate, bins=30, edgecolor=\"black\", alpha=0.7, color=\"coral\")\n",
    "ax1.set_xlabel(\"Missing Rate\")\n",
    "ax1.set_ylabel(\"Number of Samples\")\n",
    "ax1.set_title(\"Sample Missing Rate Distribution\")\n",
    "\n",
    "# Panel 2: Number of detected features per sample\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "n_detected = container_qc.obs[\"n_detected\"].to_numpy()\n",
    "ax2.hist(n_detected, bins=30, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "ax2.set_xlabel(\"Number of Detected Features\")\n",
    "ax2.set_ylabel(\"Number of Samples\")\n",
    "ax2.set_title(\"Detected Features Distribution\")\n",
    "\n",
    "# Panel 3: Total intensity per sample\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "total_intensity = container_qc.obs[\"total_intensity\"].to_numpy()\n",
    "ax3.hist(total_intensity, bins=30, edgecolor=\"black\", alpha=0.7, color=\"seagreen\")\n",
    "ax3.set_xlabel(\"Total Intensity\")\n",
    "ax3.set_ylabel(\"Number of Samples\")\n",
    "ax3.set_title(\"Total Intensity Distribution\")\n",
    "\n",
    "# Panel 4: Batch comparison - missing rate\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "if \"batch\" in container_qc.obs.columns:\n",
    "    batch_missing = (\n",
    "        container_qc.obs.group_by(\"batch\")\n",
    "        .agg(pl.col(\"missing_rate\").mean().alias(\"mean_missing\"))\n",
    "        .sort(\"batch\")\n",
    "    )\n",
    "    ax4.bar(\n",
    "        batch_missing[\"batch\"].to_list(),\n",
    "        batch_missing[\"mean_missing\"].to_list(),\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax4.set_xlabel(\"Batch\")\n",
    "    ax4.set_ylabel(\"Mean Missing Rate\")\n",
    "    ax4.set_title(\"Missing Rate by Batch\")\n",
    "\n",
    "# Panel 5: Batch comparison - detected features\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "if \"batch\" in container_qc.obs.columns:\n",
    "    batch_detected = (\n",
    "        container_qc.obs.group_by(\"batch\")\n",
    "        .agg(pl.col(\"n_detected\").mean().alias(\"mean_detected\"))\n",
    "        .sort(\"batch\")\n",
    "    )\n",
    "    ax5.bar(\n",
    "        batch_detected[\"batch\"].to_list(),\n",
    "        batch_detected[\"mean_detected\"].to_list(),\n",
    "        color=\"steelblue\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax5.set_xlabel(\"Batch\")\n",
    "    ax5.set_ylabel(\"Mean Detected Features\")\n",
    "    ax5.set_title(\"Detected Features by Batch\")\n",
    "\n",
    "# Panel 6: Batch comparison - total intensity\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "if \"batch\" in container_qc.obs.columns:\n",
    "    batch_intensity = (\n",
    "        container_qc.obs.group_by(\"batch\")\n",
    "        .agg(pl.col(\"total_intensity\").mean().alias(\"mean_intensity\"))\n",
    "        .sort(\"batch\")\n",
    "    )\n",
    "    ax6.bar(\n",
    "        batch_intensity[\"batch\"].to_list(),\n",
    "        batch_intensity[\"mean_intensity\"].to_list(),\n",
    "        color=\"seagreen\",\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax6.set_xlabel(\"Batch\")\n",
    "    ax6.set_ylabel(\"Mean Total Intensity\")\n",
    "    ax6.set_title(\"Total Intensity by Batch\")\n",
    "\n",
    "# Panel 7: Feature missing rate distribution\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "feature_missing = container_qc.assays[\"proteins\"].var[\"prevalence\"].to_numpy()\n",
    "ax7.hist(feature_missing, bins=30, edgecolor=\"black\", alpha=0.7, color=\"orange\")\n",
    "ax7.set_xlabel(\"Prevalence (proportion of samples)\")\n",
    "ax7.set_ylabel(\"Number of Features\")\n",
    "ax7.set_title(\"Feature Prevalence Distribution\")\n",
    "\n",
    "# Panel 8: Feature variance distribution\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "feature_var = container_qc.assays[\"proteins\"].var[\"variance\"].to_numpy()\n",
    "ax8.hist(feature_var, bins=30, edgecolor=\"black\", alpha=0.7, color=\"purple\")\n",
    "ax8.set_xlabel(\"Variance\")\n",
    "ax8.set_ylabel(\"Number of Features\")\n",
    "ax8.set_title(\"Feature Variance Distribution\")\n",
    "\n",
    "# Panel 9: Feature mean intensity vs variance\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "feature_mean = container_qc.assays[\"proteins\"].var[\"mean_intensity\"].to_numpy()\n",
    "scatter = ax9.scatter(feature_mean, feature_var, alpha=0.5, s=20, c=\"darkblue\")\n",
    "ax9.set_xlabel(\"Mean Intensity\")\n",
    "ax9.set_ylabel(\"Variance\")\n",
    "ax9.set_title(\"Mean-Variance Relationship\")\n",
    "ax9.set_xscale(\"log\")\n",
    "ax9.set_yscale(\"log\")\n",
    "\n",
    "# Overall title\n",
    "fig.suptitle(\"Comprehensive QC Summary\", fontsize=16, fontweight=\"bold\", y=0.995)\n",
    "\n",
    "plt.savefig(\"tutorial_output/comprehensive_qc_summary.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Comprehensive QC summary saved to: tutorial_output/comprehensive_qc_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "In this tutorial, you learned advanced QC techniques for single-cell proteomics data:\n",
    "\n",
    "### Sensitivity Analysis:\n",
    "- **`compute_sensitivity()`**: Total and local (per-sample) feature detection\n",
    "- **`compute_completeness()`**: Proportion of detected values per sample\n",
    "- **`compute_cumulative_sensitivity()`**: Feature saturation analysis\n",
    "- **`compute_jaccard_index()`**: Sample similarity based on feature overlap\n",
    "- **`qc_report_metrics()`**: Generate comprehensive QC reports\n",
    "\n",
    "### Missing Value Analysis:\n",
    "- **`analyze_missing_types()`**: Analyze mask matrix for different missing types\n",
    "- **`compute_missing_stats()`**: Comprehensive missing value statistics\n",
    "- **`report_missing_values()`**: Generate missing value reports by group\n",
    "\n",
    "### Variability Analysis:\n",
    "- **`compute_cv()`**: Coefficient of variation per feature\n",
    "- **`compute_batch_cv()`**: Within-batch and between-batch CV\n",
    "- **`filter_by_cv()`**: Filter features by CV threshold\n",
    "\n",
    "### Advanced Detection:\n",
    "- **`detect_contaminants()`**: Identify common contaminant proteins\n",
    "- **`detect_doublets()`**: Detect potential multiplets/doublets\n",
    "\n",
    "### Best Practices:\n",
    "1. **Start with sensitivity analysis** to understand overall data quality\n",
    "2. **Use cumulative sensitivity** to assess if you have enough samples\n",
    "3. **Analyze missing types** to understand the nature of missing values\n",
    "4. **Check batch effects** using batch CV analysis\n",
    "5. **Detect and remove contaminants** before downstream analysis\n",
    "6. **Filter high CV features** carefully - they may be biologically relevant\n",
    "7. **Always visualize QC metrics** before and after filtering\n",
    "\n",
    "### Next Steps:\n",
    "- **Tutorial 03**: Imputation and Batch Correction\n",
    "- **Tutorial 04**: Clustering and Visualization\n",
    "- **Tutorial 05**: Differential Expression Analysis\n",
    "- **Tutorial 07**: Feature Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

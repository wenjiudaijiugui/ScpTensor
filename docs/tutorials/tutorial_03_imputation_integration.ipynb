{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 03: Imputation and Batch Integration\n",
    "\n",
    "This tutorial covers missing value imputation and batch effect correction for single-cell proteomics data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "- Understand missing value patterns in SCP data (MCAR vs MNAR)\n",
    "- Apply various imputation methods (KNN, PPCA, SVD, MissForest)\n",
    "- Detect and assess batch effects\n",
    "- Apply batch correction methods (ComBat, Harmony, MNN)\n",
    "- Evaluate the effectiveness of imputation and integration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import required libraries and load an example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Apply SciencePlots style\n",
    "plt.style.use([\"science\", \"no-latex\"])\n",
    "\n",
    "# Import ScpTensor\n",
    "import scptensor\n",
    "from scptensor.datasets import load_simulated_scrnaseq_like\n",
    "from scptensor import (\n",
    "    # Imputation\n",
    "    knn,\n",
    "    ppca,\n",
    "    svd_impute,\n",
    "    missforest,\n",
    "    # Integration\n",
    "    combat,\n",
    "    harmony,\n",
    "    mnn_correct,\n",
    "    # QC and utilities\n",
    "    count_mask_codes,\n",
    "    MaskCode,\n",
    "    calculate_qc_metrics,\n",
    "    # Normalization\n",
    "    log_normalize,\n",
    "    zscore,\n",
    ")\n",
    "\n",
    "print(f\"ScpTensor version: {scptensor.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "Let's load a dataset with batch effects and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "container = load_simulated_scrnaseq_like()\n",
    "\n",
    "print(f\"Dataset loaded: {container}\")\n",
    "print(f\"Samples: {container.n_samples}\")\n",
    "print(f\"Features: {container.assays['proteins'].n_features}\")\n",
    "\n",
    "# Check batch distribution\n",
    "print(\"\\nBatch distribution:\")\n",
    "print(container.obs.group_by(\"batch\").count().sort(\"batch\"))\n",
    "\n",
    "# Check cell type distribution\n",
    "print(\"\\nCell type distribution:\")\n",
    "print(container.obs.group_by(\"cell_type\").count().sort(\"cell_type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding Missing Values\n",
    "\n",
    "### 3.1 Missing Value Patterns\n",
    "\n",
    "Single-cell proteomics data has two types of missing values:\n",
    "\n",
    "- **MCAR (Missing Completely At Random)**: Technical dropout, unrelated to intensity\n",
    "- **MNAR (Missing Not At Random)**: Limit of detection (LOD), related to low intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze missing value patterns\n",
    "matrix = container.assays[\"proteins\"].layers[\"raw\"]\n",
    "mask_counts = count_mask_codes(matrix.M)\n",
    "\n",
    "print(\"Missing Value Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total values: {matrix.M.size}\")\n",
    "print(f\"Valid values (0): {mask_counts.get(0, 0)} ({mask_counts.get(0, 0)/matrix.M.size*100:.1f}%)\")\n",
    "print(f\"MCAR/MBR (1): {mask_counts.get(1, 0)} ({mask_counts.get(1, 0)/matrix.M.size*100:.1f}%)\")\n",
    "print(f\"MNAR/LOD (2): {mask_counts.get(2, 0)} ({mask_counts.get(2, 0)/matrix.M.size*100:.1f}%)\")\n",
    "\n",
    "# Overall missing rate\n",
    "missing_rate = (matrix.M != 0).sum() / matrix.M.size\n",
    "print(f\"\\nOverall missing rate: {missing_rate * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualize Missing Value Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing value patterns\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "gs = GridSpec(3, 3, figure=fig)\n",
    "\n",
    "# Missing rate per sample\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "sample_missing = (matrix.M != 0).sum(axis=1) / matrix.M.shape[1]\n",
    "ax1.bar(range(len(sample_missing)), sample_missing, color='steelblue')\n",
    "ax1.set_xlabel('Sample Index')\n",
    "ax1.set_ylabel('Missing Rate')\n",
    "ax1.set_title('Missing Rate per Sample')\n",
    "\n",
    "# Missing rate per feature\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "feature_missing = (matrix.M != 0).sum(axis=0) / matrix.M.shape[0]\n",
    "ax2.hist(feature_missing, bins=30, color='coral', edgecolor='black')\n",
    "ax2.set_xlabel('Missing Rate')\n",
    "ax2.set_ylabel('Number of Features')\n",
    "ax2.set_title('Distribution of Missing Rate per Feature')\n",
    "\n",
    "# Missing by batch\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "batch_missing = []\n",
    "batch_labels = sorted(container.obs[\"batch\"].unique().to_list())\n",
    "for batch in batch_labels:\n",
    "    batch_samples = container.obs.filter(pl.col(\"batch\") == batch)[\"sample_id\"].to_list()\n",
    "    # Get indices for this batch\n",
    "    batch_indices = [i for i, sid in enumerate(container.obs[\"sample_id\"].to_list()) if sid in batch_samples]\n",
    "    batch_mr = sample_missing[batch_indices].mean()\n",
    "    batch_missing.append(batch_mr)\n",
    "\n",
    "ax3.bar(range(len(batch_labels)), batch_missing, color='lightgreen')\n",
    "ax3.set_xticks(range(len(batch_labels)))\n",
    "ax3.set_xticklabels(batch_labels)\n",
    "ax3.set_ylabel('Mean Missing Rate')\n",
    "ax3.set_title('Missing Rate by Batch')\n",
    "\n",
    "# Spy plot (missing pattern)\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "missing_mask = (matrix.M != 0).astype(float)\n",
    "ax4.imshow(missing_mask[:100, :100], aspect='auto', cmap='Reds', interpolation='none')\n",
    "ax4.set_xlabel('Feature Index')\n",
    "ax4.set_ylabel('Sample Index')\n",
    "ax4.set_title('Missing Value Pattern (Spy Plot) - First 100 samples x 100 features')\n",
    "\n",
    "# Intensity vs missing probability\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "X_flat = matrix.X.flatten()\n",
    "M_flat = matrix.M.flatten()\n",
    "\n",
    "# Bin by intensity and compute missing rate\n",
    "percentiles = np.percentile(X_flat[M_flat == 0], np.linspace(0, 100, 20))\n",
    "missing_by_intensity = []\n",
    "intensity_bins = []\n",
    "\n",
    "for i in range(len(percentiles) - 1):\n",
    "    mask = (X_flat >= percentiles[i]) & (X_flat < percentiles[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        missing_by_intensity.append((M_flat[mask] != 0).mean())\n",
    "        intensity_bins.append((percentiles[i] + percentiles[i+1]) / 2)\n",
    "\n",
    "ax5.plot(intensity_bins, missing_by_intensity, 'o-', color='darkred')\n",
    "ax5.set_xlabel('Intensity')\n",
    "ax5.set_ylabel('Missing Rate')\n",
    "ax5.set_title('Missing Rate vs Intensity (MNAR pattern)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/missing_patterns.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Missing pattern visualizations saved to: tutorial_output/missing_patterns.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Imputation Methods\n",
    "\n",
    "### 4.1 Preprocessing: Log Normalization\n",
    "\n",
    "First, let's apply log normalization to stabilize variance before imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log normalization\n",
    "container = log_normalize(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"raw\",\n",
    "    new_layer_name=\"log\",\n",
    "    base=2.0,\n",
    "    offset=1.0,\n",
    ")\n",
    "\n",
    "print(\"Log normalization completed.\")\n",
    "print(f\"Available layers: {list(container.assays['proteins'].layers.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 K-Nearest Neighbors (KNN) Imputation\n",
    "\n",
    "KNN imputation fills missing values using the average of k nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KNN imputation\n",
    "print(\"Running KNN imputation (this may take a moment)...\")\n",
    "\n",
    "container = knn(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"log\",\n",
    "    new_layer_name=\"knn_imputed\",\n",
    "    k=10,  # Number of neighbors\n",
    ")\n",
    "\n",
    "print(\"KNN imputation completed.\")\n",
    "\n",
    "# Check the result\n",
    "knn_matrix = container.assays[\"proteins\"].layers[\"knn_imputed\"]\n",
    "knn_missing_rate = (knn_matrix.M != 0).sum() / knn_matrix.M.size\n",
    "print(f\"Missing rate after KNN imputation: {knn_missing_rate * 100:.2f}%\")\n",
    "print(f\"Imputed values marked with mask code 5: {(knn_matrix.M == 5).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Probabilistic PCA (PPCA) Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PPCA imputation\n",
    "print(\"Running PPCA imputation...\")\n",
    "\n",
    "container = ppca(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"log\",\n",
    "    new_layer_name=\"ppca_imputed\",\n",
    "    n_components=10,  # Number of principal components\n",
    ")\n",
    "\n",
    "print(\"PPCA imputation completed.\")\n",
    "\n",
    "# Check the result\n",
    "ppca_matrix = container.assays[\"proteins\"].layers[\"ppca_imputed\"]\n",
    "print(f\"Missing rate after PPCA: {(ppca_matrix.M != 0).sum() / ppca_matrix.M.size * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 SVD Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SVD imputation\n",
    "print(\"Running SVD imputation...\")\n",
    "\n",
    "container = svd_impute(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"log\",\n",
    "    new_layer_name=\"svd_imputed\",\n",
    "    rank=10,  # Rank for SVD approximation\n",
    ")\n",
    "\n",
    "print(\"SVD imputation completed.\")\n",
    "\n",
    "# Check the result\n",
    "svd_matrix = container.assays[\"proteins\"].layers[\"svd_imputed\"]\n",
    "print(f\"Missing rate after SVD: {(svd_matrix.M != 0).sum() / svd_matrix.M.size * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 MissForest Imputation (Random Forest)\n",
    "\n",
    "MissForest uses an iterative random forest approach for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MissForest imputation\n",
    "# Note: This is slower than other methods\n",
    "print(\"Running MissForest imputation (this may take longer)...\")\n",
    "\n",
    "try:\n",
    "    container = missforest(\n",
    "        container,\n",
    "        assay_name=\"proteins\",\n",
    "        base_layer=\"log\",\n",
    "        new_layer_name=\"mf_imputed\",\n",
    "        max_iter=10,  # Maximum iterations\n",
    "        n_estimators=50,  # Number of trees\n",
    "    )\n",
    "    print(\"MissForest imputation completed.\")\n",
    "    \n",
    "    # Check the result\n",
    "    mf_matrix = container.assays[\"proteins\"].layers[\"mf_imputed\"]\n",
    "    print(f\"Missing rate after MissForest: {(mf_matrix.M != 0).sum() / mf_matrix.M.size * 100:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"MissForest imputation skipped: {e}\")\n",
    "    print(\"(MissForest requires scikit-learn to be installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare imputation results\n",
    "imputed_layers = ['log', 'knn_imputed', 'ppca_imputed', 'svd_imputed']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for i, layer in enumerate(imputed_layers):\n",
    "    if layer in container.assays['proteins'].layers:\n",
    "        X = container.assays['proteins'].layers[layer].X\n",
    "        ax = axes[i // 2, i % 2]\n",
    "        \n",
    "        # Plot distribution of first 1000 values\n",
    "        ax.hist(X.flatten()[:1000], bins=50, alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(f'{layer.replace(\"_\", \" \").title()}')\n",
    "        ax.set_xlabel('Intensity')\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/imputation_comparison.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Imputation comparison saved to: tutorial_output/imputation_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Effect Detection\n",
    "\n",
    "Before batch correction, let's detect batch effects using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scptensor import pca\n",
    "\n",
    "# Run PCA on imputed data to visualize batch effects\n",
    "container = pca(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer_name=\"knn_imputed\",\n",
    "    new_assay_name=\"pca_pre_correction\",\n",
    "    n_components=10,\n",
    ")\n",
    "\n",
    "# Get PCA coordinates\n",
    "pc1 = container.assays[\"pca_pre_correction\"].layers[\"scores\"].X[:, 0]\n",
    "pc2 = container.assays[\"pca_pre_correction\"].layers[\"scores\"].X[:, 1]\n",
    "\n",
    "# Visualize batch effects\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Color by batch\n",
    "batches = container.obs[\"batch\"].to_numpy()\n",
    "unique_batches = sorted(container.obs[\"batch\"].unique().to_list())\n",
    "colors_batch = plt.cm.tab10(np.linspace(0, 1, len(unique_batches)))\n",
    "\n",
    "for batch, color in zip(unique_batches, colors_batch):\n",
    "    mask = batches == batch\n",
    "    axes[0].scatter(pc1[mask], pc2[mask], c=[color], label=batch, alpha=0.6, s=30)\n",
    "\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('PCA Colored by Batch (Before Correction)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Color by cell type\n",
    "cell_types = container.obs[\"cell_type\"].to_numpy()\n",
    "unique_celltypes = sorted(container.obs[\"cell_type\"].unique().to_list())\n",
    "colors_ct = plt.cm.Set2(np.linspace(0, 1, len(unique_celltypes)))\n",
    "\n",
    "for ct, color in zip(unique_celltypes, colors_ct):\n",
    "    mask = cell_types == ct\n",
    "    axes[1].scatter(pc1[mask], pc2[mask], c=[color], label=ct, alpha=0.6, s=30)\n",
    "\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('PCA Colored by Cell Type (Before Correction)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/pca_before_correction.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"PCA visualization saved to: tutorial_output/pca_before_correction.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Correction Methods\n",
    "\n",
    "### 7.1 ComBat (Empirical Bayes)\n",
    "\n",
    "ComBat is a popular batch correction method using empirical Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply ComBat batch correction\n",
    "print(\"Running ComBat batch correction...\")\n",
    "\n",
    "container = combat(\n",
    "    container,\n",
    "    batch_key=\"batch\",\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer=\"knn_imputed\",\n",
    "    new_layer_name=\"combat_corrected\",\n",
    ")\n",
    "\n",
    "print(\"ComBat correction completed.\")\n",
    "\n",
    "# Run PCA on corrected data\n",
    "container = pca(\n",
    "    container,\n",
    "    assay_name=\"proteins\",\n",
    "    base_layer_name=\"combat_corrected\",\n",
    "    new_assay_name=\"pca_combat\",\n",
    "    n_components=10,\n",
    ")\n",
    "\n",
    "# Get PCA coordinates\n",
    "pc1_combat = container.assays[\"pca_combat\"].layers[\"scores\"].X[:, 0]\n",
    "pc2_combat = container.assays[\"pca_combat\"].layers[\"scores\"].X[:, 1]\n",
    "\n",
    "print(\"PCA on ComBat-corrected data completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualizing ComBat Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ComBat correction\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Before correction - by batch\n",
    "for batch, color in zip(unique_batches, colors_batch):\n",
    "    mask = batches == batch\n",
    "    axes[0, 0].scatter(pc1[mask], pc2[mask], c=[color], label=batch, alpha=0.6, s=30)\n",
    "axes[0, 0].set_xlabel('PC1')\n",
    "axes[0, 0].set_ylabel('PC2')\n",
    "axes[0, 0].set_title('Before ComBat: By Batch')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Before correction - by cell type\n",
    "for ct, color in zip(unique_celltypes, colors_ct):\n",
    "    mask = cell_types == ct\n",
    "    axes[0, 1].scatter(pc1[mask], pc2[mask], c=[color], label=ct, alpha=0.6, s=30)\n",
    "axes[0, 1].set_xlabel('PC1')\n",
    "axes[0, 1].set_ylabel('PC2')\n",
    "axes[0, 1].set_title('Before ComBat: By Cell Type')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# After correction - by batch\n",
    "for batch, color in zip(unique_batches, colors_batch):\n",
    "    mask = batches == batch\n",
    "    axes[1, 0].scatter(pc1_combat[mask], pc2_combat[mask], c=[color], label=batch, alpha=0.6, s=30)\n",
    "axes[1, 0].set_xlabel('PC1')\n",
    "axes[1, 0].set_ylabel('PC2')\n",
    "axes[1, 0].set_title('After ComBat: By Batch')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# After correction - by cell type\n",
    "for ct, color in zip(unique_celltypes, colors_ct):\n",
    "    mask = cell_types == ct\n",
    "    axes[1, 1].scatter(pc1_combat[mask], pc2_combat[mask], c=[color], label=ct, alpha=0.6, s=30)\n",
    "axes[1, 1].set_xlabel('PC1')\n",
    "axes[1, 1].set_ylabel('PC2')\n",
    "axes[1, 1].set_title('After ComBat: By Cell Type')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/combat_correction.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"ComBat visualization saved to: tutorial_output/combat_correction.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 MNN Correction (Mutual Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply MNN correction\n",
    "print(\"Running MNN correction...\")\n",
    "\n",
    "try:\n",
    "    container = mnn_correct(\n",
    "        container,\n",
    "        batch_key=\"batch\",\n",
    "        assay_name=\"proteins\",\n",
    "        base_layer=\"knn_imputed\",\n",
    "        new_layer_name=\"mnn_corrected\",\n",
    "        k=20,  # Number of nearest neighbors\n",
    "        sigma=1.0,  # MNN kernel bandwidth\n",
    "    )\n",
    "    \n",
    "    print(\"MNN correction completed.\")\n",
    "    \n",
    "    # Run PCA on MNN corrected data\n",
    "    container = pca(\n",
    "        container,\n",
    "        assay_name=\"proteins\",\n",
    "        base_layer_name=\"mnn_corrected\",\n",
    "        new_assay_name=\"pca_mnn\",\n",
    "        n_components=10,\n",
    "    )\n",
    "    \n",
    "    pc1_mnn = container.assays[\"pca_mnn\"].layers[\"scores\"].X[:, 0]\n",
    "    pc2_mnn = container.assays[\"pca_mnn\"].layers[\"scores\"].X[:, 1]\n",
    "    \n",
    "    print(\"PCA on MNN-corrected data completed.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"MNN correction skipped: {e}\")\n",
    "    pc1_mnn, pc2_mnn = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Harmony Integration\n",
    "\n",
    "Harmony uses an iterative clustering approach for batch correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Harmony integration (requires harmonypy)\n",
    "print(\"Running Harmony integration...\")\n",
    "\n",
    "try:\n",
    "    container = harmony(\n",
    "        container,\n",
    "        batch_key=\"batch\",\n",
    "        assay_name=\"pca_pre_correction\",\n",
    "        base_layer=\"scores\",\n",
    "        new_layer_name=\"harmony_scores\",\n",
    "        lambda_val=1.0,  # Clustering penalty\n",
    "        theta_val=2.0,  # Diversity penalty\n",
    "    )\n",
    "    \n",
    "    print(\"Harmony integration completed.\")\n",
    "    \n",
    "    # Get Harmony coordinates\n",
    "    harm1 = container.assays[\"pca_pre_correction\"].layers[\"harmony_scores\"].X[:, 0]\n",
    "    harm2 = container.assays[\"pca_pre_correction\"].layers[\"harmony_scores\"].X[:, 1]\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Harmony integration skipped: {e}\")\n",
    "    print(\"(Harmony requires harmonypy to be installed: pip install harmonypy)\")\n",
    "    harm1, harm2 = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Quantifying Batch Effect Removal\n",
    "\n",
    "Let's quantify how well each method removed batch effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate batch effect strength (PC1 variance explained by batch)\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "def batch_effect_strength(pc, batches):\n",
    "    \"\"\"\n",
    "    Calculate batch effect strength using ANOVA F-statistic.\n",
    "    Higher values indicate stronger batch effects.\n",
    "    \"\"\"\n",
    "    groups = [pc[batches == b] for b in np.unique(batches)]\n",
    "    f_stat, _ = f_oneway(*groups)\n",
    "    return f_stat\n",
    "\n",
    "# Calculate batch effect strength for each method\n",
    "results = []\n",
    "methods = []\n",
    "\n",
    "# Before correction\n",
    "be_before = batch_effect_strength(pc1, batches)\n",
    "results.append(be_before)\n",
    "methods.append('Before Correction')\n",
    "\n",
    "# After ComBat\n",
    "be_combat = batch_effect_strength(pc1_combat, batches)\n",
    "results.append(be_combat)\n",
    "methods.append('ComBat')\n",
    "\n",
    "# After MNN\n",
    "if pc1_mnn is not None:\n",
    "    be_mnn = batch_effect_strength(pc1_mnn, batches)\n",
    "    results.append(be_mnn)\n",
    "    methods.append('MNN')\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['coral', 'skyblue', 'lightgreen'][:len(methods)]\n",
    "bars = ax.bar(methods, results, color=colors)\n",
    "ax.set_ylabel('ANOVA F-Statistic (Batch Effect Strength)')\n",
    "ax.set_title('Batch Effect Removal Comparison')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, results):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(results)*0.01,\n",
    "            f'{val:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('tutorial_output/batch_effect_comparison.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBatch effect strength (lower is better):\")\n",
    "for method, strength in zip(methods, results):\n",
    "    print(f\"  {method:20s}: {strength:8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "### Imputation:\n",
    "1. **KNN Imputation**: Uses k-nearest neighbors (`knn()`)\n",
    "2. **PPCA Imputation**: Probabilistic PCA (`ppca()`)\n",
    "3. **SVD Imputation**: Iterative SVD (`svd_impute()`)\n",
    "4. **MissForest**: Random forest based (`missforest()`)\n",
    "\n",
    "### Batch Correction:\n",
    "1. **ComBat**: Empirical Bayes method (`combat()`)\n",
    "2. **MNN**: Mutual Nearest Neighbors (`mnn_correct()`)\n",
    "3. **Harmony**: Iterative clustering (`harmony()`)\n",
    "\n",
    "### Best Practices:\n",
    "- Always visualize missing value patterns before imputation\n",
    "- Choose imputation method based on missingness pattern (MCAR vs MNAR)\n",
    "- Apply log normalization before most imputation methods\n",
    "- Use KNN for smaller datasets, PPCA/SVD for larger datasets\n",
    "- Always verify batch correction results visually\n",
    "- Preserve biological signal while removing batch effects\n",
    "\n",
    "### Choosing a Method:\n",
    "- **KNN**: Fast, works well for MCAR data\n",
    "- **PPCA/SVD**: Good for large datasets, assumes linear structure\n",
    "- **MissForest**: Best for complex patterns, but slow\n",
    "- **ComBat**: Fast and effective for most cases\n",
    "- **MNN**: Preserves local structure well\n",
    "- **Harmony**: Good for integrating multiple batches\n",
    "\n",
    "### Next Steps:\n",
    "- **Tutorial 04**: Clustering and Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

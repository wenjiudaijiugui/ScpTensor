name: Nightly Benchmarks

on:
  schedule:
    # Run at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  FORCE_COLOR: 1
  UV_CACHE_DIR: ${{ github.workspace }}/.cache/uv

jobs:
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache UV packages
        uses: actions/cache@v4
        with:
          path: |
            .venv
            ${{ env.UV_CACHE_DIR }}
          key: ${{ runner.os }}-py312-bench-uv-${{ hashFiles('pyproject.toml', 'uv.lock') }}
          restore-keys: |
            ${{ runner.os }}-py312-bench-uv-

      - name: Install dependencies
        run: |
          uv sync --all-extras
          uv sync --group dev

      - name: Run JIT benchmarks
        run: |
          uv run python tests/benchmark_jit.py

      - name: Run sparse matrix benchmarks
        run: |
          uv run python tests/benchmark_sparse_operations.py

      - name: Run log transformation benchmarks
        run: |
          uv run python tests/benchmark_log_jit.py

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.run_number }}
          path: |
            tests/pipeline_results/
            tests/comparison_results/
          retention-days: 30

  regression-test:
    name: Performance Regression Test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          uv sync --all-extras
          uv sync --group dev

      - name: Run speedup benchmarks
        run: |
          uv run python tests/benchmark_jit_speedup.py

      - name: Check for performance degradation
        run: |
          # This is a placeholder - implement actual regression detection
          echo "Performance regression checks passed"
